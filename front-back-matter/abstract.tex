\frontmattersection{Abstract}

%Inference, the process of drawing conclusions from evidence, is at the heart of the scientific method. Probability theory offers a consistent framework for performing inference in the presence of uncertainty, posing the inference problem as the task of computing integrals of functions of interest with respect to a probability measure. In complex models with a large numbers of latent variables to infer, these integrals will usually be intractable to compute exactly. This has motivated the development of approximate inference methods which tradeoff a lack of exactness for greater computational tractability. 

%\ac{MCMC} methods are a widely applicable class of approximate inference approaches for estimating integrals in statistical inference problems.



% one such class of techniques, with a Markov chain constructed which converges to generating dependent samples from the target distribution of interest. The sequence of sampled chain states are then used to form Monte Carlo estimates of quantities of interest. Several general purpose algorithms have been proposed for constructing Markov chains which converge to a desired target distribution including the seminal Metropolis--Hastings method of Metropolis et al. (1953) and Hastings (1970) and the Gibbs sampling method of Geman and Geman (1984).%, and \ac{MCMC} methods have been successfully applied to perform inference in a huge range of probabilistic models.	x

%A common approach in \ac{MCMC} methods is to introduce additional auxiliary variables in to the chain state and perform transitions in the joint space of target and auxiliary variables. %The slice sampling algorithms of Neal 2003 and Murray et al. 2010 

%while algorithms such as simulated tempering use an auxiliary variable formulation to improve sampling from complex multimodal target distributions and to allow estimation of their normalising constants.


%construct a transition operator which leaves a joint distribution on the original target variables and additional auxiliary variables invariant. 

%The unifying theme of this thesis is the use of this idea of introducing auxiliary variables in to \ac{MCMC} methods
Markov chain Monte Carlo (MCMC) methods are a widely applicable class of algorithms for estimating integrals in statistical inference problems. A common approach in MCMC methods is to introduce additional auxiliary variables into the Markov chain state and perform transitions in the joint space of target and auxiliary variables. In this thesis we consider novel methods for using auxiliary variables within MCMC methods to allow approximate inference in otherwise intractable models and to improve sampling performance in models exhibiting challenging properties such as multimodality.

We first consider the pseudo-marginal framework. This extends the Metropolis–Hastings algorithm to cases where we only have access to an unbiased estimator of the density of target distribution. The resulting chains can sometimes show ‘sticking’ behaviour where long series of proposed updates are rejected. Further the algorithms can be difficult to tune and it is not immediately clear how to generalise the approach to alternative transition operators. We show that if the auxiliary variables used in the density estimator are included in the chain state it is possible to use new transition operators such as those based on slice-sampling algorithms within a pseudo-marginal setting. This auxiliary pseudo-marginal approach leads to easier to tune methods and is often able to improve sampling efficiency over existing approaches.

As a second contribution we consider inference in probabilistic models defined via a generative process with the probability density of the outputs of this process only implicitly defined. The approximate Bayesian computation (ABC) framework allows inference in such models when conditioning on the values of observed model variables by making the approximation that generated observed variables are ‘close’ rather than exactly equal to observed data. Although making the inference problem more tractable, the approximation error introduced in ABC methods can be difficult to quantify and standard algorithms tend to perform poorly when conditioning on high dimensional observations. This oftens requires further approximation by reducing the observations to lower dimensional summary statistics.

We show how including all of the random variables used in generating model outputs as auxiliary variables in a Markov chain state can allow the use of more efficient and robust MCMC methods such as slice sampling and Hamiltonian Monte Carlo (HMC) within an ABC framework. In some cases this can allow inference when conditioning on the full set of observed values when standard ABC methods require reduction to lower dimensional summaries for tractability. Further we introduce a novel constrained HMC method for performing inference in a restricted class of differentiable generative models which allows conditioning the generated observed variables to be arbitrarily close to observed data while maintaining computational tractability.

As a final topic we consider the use of an auxiliary temperature variable in MCMC methods to improve exploration of multimodal target densities and allow estimation of normalising constants. Existing approaches such as simulated tempering and annealed importance sampling use temperature variables which take on only a discrete set of values. The performance of these methods can be sensitive to the number and spacing of the temperature values used, and the discrete nature of the temperature variable prevents the use of gradient-based methods such as HMC to update the temperature alongside the target variables. We introduce new MCMC methods which instead use a continuous temperature variable. This both removes the need to tune the choice of discrete temperature values and allows the temperature variable to be updated jointly with the target variables within a HMC method. 



%\ac{MCMC} methods are a widely applicable class of approximate inference approaches for estimating integrals in statistical inference problems. A common approach in \ac{MCMC} methods is to introduce additional auxiliary variables in to the Markov chain state and perform transitions in the joint space of target and auxiliary variables. In this thesis we consider novel methods for using auxiliary variables within \ac{MCMC} methods to allow approximate inference in otherwise intractable models and to improve sampling efficiency in models exhibiting challenging properties such as multimodality.
%
%We first consider the pseudo-marginal framework. This extends the Metropolis--Hastings algorithm to cases where we only have access to an unbiased estimator of the density of target distribution. The resulting chains can sometimes show `sticking' behaviour where long series of proposed updates are rejected. Further the algorithms can be difficult to tune and it is not immediately clear how to generalise the approach to alternative transition operators. We show how including the auxiliary variables used in the density estimator in the chain state it is possible to use new transition operators such as those based on slice-sampling algorithms within a pseudo-marginal setting. This auxiliary pseudo-marginal approach leads to easier to tune methods and is often able to improve sampling efficiency over existing approaches.
%
%As a second contribution we consider inference in probabilistic models defined via a generative process with the probability density of the outputs of this process only implicitly defined. The \ac{ABC} framework allows inference in implicit generative models when conditioning on the value of model variables by making the approximation that generated observed variables are `close' rather than exactly equal to observed data. Although making the inference problem more tractable, the approximation error introduced in \ac{ABC} methods can be difficult to quantify and standard algorithms tend to perform poorly when conditioning on high dimensional observations. This oftens requires further approximation by reducing the observations to lower dimensional summary statistics. 
%
%We show how including all of the random variables used in generating model outputs as auxiliary variables in a Markov chain state can allow the use of more efficient and robust \ac{MCMC} methods such as slice sampling and \ac{HMC} within an \ac{ABC} framework. In some cases this can allow inference when conditioning on the full set of observed values when standard \ac{ABC} methods require reduction to lower dimensional summaries for tractability. Further we introduce a novel constrained \ac{HMC} method for performing inference in a restricted class of differentiable generative models such that it is possible to condition on the simulated observed variables being arbitarily close to observed data while maintaining computational tractability.
%
%As a final topic we consider the use of an auxiliary temperature variable in \ac{MCMC} methods to improve exploration of multimodal target densities and allow estimation of normalising constants. Existing approaches such as simulated tempering and annealed importance sampling use temperature variables which take on only a discrete set of values. The choice of the number and spacing of the discrete values can be key to getting these methods to perform well, and the discrete nature of the temperature variable prevents the use of gradient-based methods such as \ac{HMC} to update the temperature alongside the target variables. 
%
%We introduce new \ac{MCMC} methods which instead use a continuous temperature variable. This both removes the need to tune the choice of discrete temperature values and allows the temperature variable to be updated jointly with the target variables within a \ac{HMC} method. Finally we illustrate how using deterministic variational approximations to the target distribution density and its normalising constant within a tempering framework can significantly improve the performance of the method, this approach providing a natural way of exploiting the information offered by comparatively cheap but biased variational inference methods within an asymptoptically exact \ac{MCMC} framework.




%Monte Carlo methods are one class of such techniques, with the integrals or summations across the whole state space approximated by summations over a finite number of randomly sampled points. This maps the inference problem to that of drawing samples from, often complex, high-dimesional, probability distributions.

%Lorem ipsum at nusquam appellantur his, ut eos erant homero concluda turque. Albucius appellantur deterruisset id eam, vivendum partiendo dissentiet ei ius. Vis melius facilisis ea, sea id convenire referrentur, takimata adolescens ex duo. Ei harum argumentum per. Eam vidit exerci appetere ad, ut vel zzril intellegam interpretaris. \marginpar{This is a test margin note. Foo bar lorem ipsum.}

%Errem omnium ea per, pro \ac{MCMC} con populo ornatus cu, ex qui dicant nemore melius. No pri diam iriure euismod. Graecis eleifend appellantur quo id. Id corpora inimicus nam, facer nonummy ne pro, kasd repudiandae ei mei. Mea menandri mediocrem dissentiet cu, ex nominati imperdiet nec, sea odio duis vocent ei. Tempor everti appareat cu ius, ridens audiam an qui, aliquid admodum conceptam ne qui. Vis ea melius nostrum, mel alienum euripidis eu.