\chapter{Introduction}\label{ch:probabilistic-modelling}

%\marginpar{We are hardly able to get through one waking hour without facing some situation (e.g. will it rain or wonâ€™t it?) where we do not have enough information to permit deductive reasoning \\--- Edward Jaynes}
\marginpar{The actual science of logic is conversant at present only with things either certain, impossible, or entirely doubtful, none of which (fortunately) we have to reason on. Therefore the true logic for this world is the calculus of probabilities\\---James Clerk Maxwell}
Inference is the process of drawing conclusions from evidence. 
%Much of our lives are spent making inferences about the world given our observations of it; in particular inference is a central aspect of the scientific process. 
While deductive logic offers a framework for inferring conclusions from absolute statements of truth, it does not apply to the more typical real-world setting where the information we receive is uncertain. 
%\marginpar{Probability theory is nothing but common sense reduced to calculation. \\--- Pierre-Simon Laplace}%
To make inferences under conditions of uncertainty, we must instead turn to probability theory, which both offers a consistent framework for quantifying our beliefs and making inferences given these beliefs. %The output of the inference process is itself probabilistic, reflecting that the conclusions we make given uncertain information will themselves be subject to uncertainty. 

%Various axiomatic bases have been proposed for deriving the laws of probability. Of particular note are the Kolmogorov axioms \citep{} which are the basis for the modern measure-theoretic formulation of probability theory. Cox's theorem \citep{} and related work by Polya \citep{} and Jaynes \citep{}, offers an alternative axiomatic basis for deriving probability theory from a minimal set of `common-sense' postulates, with resulting system of \emph{plausible reasoning} seen as natural extension of formal deductive logic under conditions of uncertainty. There has been much philosophical debate over the interpretation of probabilties

%\marginpar{Probability theory is nothing but common sense reduced to calculation. \\--- Pierre-Simon Laplace}
The key computational task in inference is computing integrals with respect to probability distributions on the variables in a proposed model. Typically these integrals will not have analytic solutions and the large number of variables being integrated over mean numerical quadrature methods are impractically costly. In these cases we must resort to approximate methods which trade-off an introduction of error for an increase in computational tractability. \ac{MCMC} methods are a very generally applicable class of approximate inference techniques which estimate the integrals of interest by computing averages over the states of a Markov chain. 

The topic of this thesis is the development of \ac{MCMC} methods. In particular we introduce several novel methods which exploit reparameterisations and augmentations of the state of a Markov chain to improve upon the computational efficiency, ease of use or degree of approximation error of existing approaches.

%and in some cases allow inference in models were existing methods cannot be applied. 

In this chapter we discuss the basic concepts of probabilistic modelling which underpin the inference methods discussed in later chapters. In particular we review the terminology and basic concepts of the measure-theoretic description of probability as some of the later results in the thesis are most clearly described within this framework. We also introduce graphical models as a compact way of visualising structure in probabilistic models. Finally we conclude with a discussion of the specific inference problems that the methods presented in the rest of this thesis are intended to help tackle.

%aimed at computing approximate solutions to.

%The topic of this thesis is methods for performing approximate inference in probabilistic models with challenging, with we in particular concentrating on the class of Markov chain Monte Carlo methods which we will introduce in the following chapter. In this chapter we will discuss the basic concepts of probabilistic modelling which will underpin the inference methods discussed in later chapters. 

%We will here largely ignore philosophical disucssions of interpretations of probabilities, and instead concentrate on the computational aspects of performing probabilistic inference.

\newpage 
\section{Probability theory}\label{sec:probability-theory}

\marginpar{A $\sigma$-algebra, $\sset{E}$, on a set $\set{S}$ is set of subsets of $\set{S}$ with $\set{S} \in \sset{E}$, $\emptyset \in \sset{E}$ and which is closed under complement and countable unions and intersections.}
A \emph{probability space} is defined as a triplet $(\set{S},\,\sset{E},\,\probability)$ where

\begin{itemize}
  \item $\set{S}$ is the \emph{sample space}, the set of all possible outcomes,
  \item $\sset{E}$ is the \emph{event space}, a $\sigma$-algebra on $\set{S}$, defining all possible events (measurable subsets of $\set{S}$),
  \item $\probability$ is the \emph{probability measure}, a finite measure satisfying $\probability(\set{S}) = 1$, which specifies the probabilities of events in $\sset{E}$.
\end{itemize}

\marginpar{\raggedright
Kolmogorov's axioms:
  \begin{enumerate}[leftmargin=0pt]
    \item Non-negativity: $\probability(\set{E}) \geq 0 ~\forall \set{E} \in \sset{E}$, 
    \item Normalisation: $\probability(\set{S}) = 1$, 
    \item Countable additivity: for any countable set of disjoint events 
    $\fset{\set{E}_i}_i :$ $\set{E}_i \in \sset{F} ~\forall i$, 
    $\set{E}_i \cap \set{E}_j = \emptyset ~\forall i \neq j$, 
    $\probability\lpa \cup_i \set{E}_i\rpa = \sum_{i} \probability(\set{E}_i)$.
  \end{enumerate}
}
%\marginpar{Kolmogorov's axioms\\1. The probability of an event is real and non-negative. \\2. The probability of the sample space is 1. \\3. The probability of any countable set of mutually exclusive events is equal to the sum of the individual event probabilties.}
Given this definition of a probability space, Kolmogorov's axioms \citep{kolmogorov1950foundations} can be used to derive a measure-theoretic formulation of probability theory. The probability of an event $\set{E} \in \sset{E}$ is defined as its measure $\probability(\set{E})$. Two events $\set{A},\set{B} \in \sset{E}$ are \emph{independent} if $\probability(\set{A}\cap\set{B}) = \probability(\set{A})\probability(\set{B})$.

The key advantage of the measure-theoretic approach to probability is that it provides a consistent definition of the probability of an event in any space we can define a measure on. This allows a unified treatment of the common cases of probability distributions of discrete and continuous random variables but also makes it possible to consider distributions on more general spaces. In Chapter \ref{ch:differentiable-generative-models} we will consider problems which involve distributions on implicitly-defined manifolds where this generality will be key to understanding the proposed methods.

% A measure-theoretic approach has the advantage of providing a unified treatment for describing probabilities on both finite and infinite sample spaces. Although alternative derivations of the laws of probability from different premises such as Cox's theorem \citep{cox1946probability,cox1963algebra} have been proposed, modern extensions of this work result in a calculus of probabilities that is equivalent to Kolmogorov's \citep{terenin2015cox}, with the differences mainly being in the philosophical interpretations of probabilities.

\subsection{Random variables}\label{subsec:random-variables}

\marginpar{If $(\set{X},\,\sset{F})$ and $(\set{Y},\,\sset{G})$ are two measurable spaces, a function $f : \set{X} \to \set{Y}$ is measurable if $f^{-1}(\set{E}) \in \sset{F}$ $\forall \set{E} \in \sset{G}$.}
When modelling real-world processes, rather than considering events as subsets of an abstract sample space, it is usually more helpful to consider \emph{random variables} which represent quantities in the model of interest. A random variable $\rvar{x} : \set{S} \to \set{X}$ is defined as a measurable function from the sample space to a measurable space $(\set{X},\,\sset{F})$. 

\marginpar{The Borel $\sigma$-algebra $\borel(\reals)$ is the smallest $\sigma$-algebra on $\reals$ which contains all open real intervals.}
Often $\set{X}$ is the reals, $\reals$, and $\sset{F}$ is the Borel $\sigma$-algebra on the reals, $\borel(\reals)$, in which case we refer to a \emph{real random variable}. It is also common to consider cases where $\set{X}$ is a real vector space, $\reals^D$, and $\sset{F} = \borel(\reals^D)$ - in this case refer to a \emph{real random vector} and use the notation $\rvct{x} : \set{S} \to \set{X}$. A final specific case is when $\set{X}$ is countable and $\sset{F}$ is the power set $\powerset(\set{X})$ in which case we refer to $\rvar{x}$ as a \emph{discrete random variable}. As we are most often concerned with real-valued random variables and vectors in this thesis, when it is unambiguous to do so we drop the `real' qualifier and simply refer to \emph{random variables} and \emph{random vectors}.

\marginpar{If $(\set{X},\,\sset{F})$ and $(\set{Y},\,\sset{G})$ are two measurable spaces, $\mu$ a measure on these spaces and $f : \set{X} \to \set{Y}$ a measurable function, the pushforward measure $\mu_f$ satisfies $\mu_f(\set{A}) = \mu \circ f^{-1}(\set{A})$ $\forall \set{A} \in \sset{G}$.}
Due to the definition of a random variable as a measurable function, we can define a pushforward measure on a random variable $\rvar{x}$
\begin{equation}
  \prob{\rvar{x}}(A) 
  = \probability\circ\rvar{x}^{-1}(\set{A})
  = \probability\lpa \lbr s \in \set{S}: \rvar{x}(s) \in A \rbr \rpa
  \quad \forall \set{A} \in \sset{F}.
\end{equation}
The measure $\prob{\rvar{x}}$ specifies that the probability of the event that the random variable $\rvar{x}$ takes a value in a measurable set $\set{A} \in \sset{F}$ is $\prob{\rvar{x}}(\set{A})$. We typically describe $\prob{\rvar{x}}$ as the \emph{distribution} of $\rvar{x}$.

%Random variables will play a central role in the explanation of the work in this thesis. We will consider a random variable to represent a quantity we are uncertain about the value of; that uncertainty may be considered to arise from incomplete knowledge of the quantity or it having a fundamentally stochastic nature, this is mainly an issue of interpretation which we will largely sidestep.

\subsection{Joint and conditional probability}\label{subsec:joint-and-conditional-probabilities}

Typically we will jointly define multiple random variables on the same probability space. Let $(\set{S},\,\sset{E},\,\probability)$ be a probability space and $\rvar{x} : \set{S} \to \set{X}$, $\rvar{y} : \set{S} \to \set{Y}$ be two random variables with corresponding $\sigma$-algebras $\sset{F}$ and $\sset{G}$. Then the \emph{joint probability} of $\rvar{x}$ and $\rvar{y}$ is defined as
\begin{equation}\label{eq:joint-probability-rvar}
  \prob{\rvar{x},\rvar{y}}(\set{A},\,\set{B}) = 
  \probability\lpa \rvar{x}^{-1}(\set{A}) \cap \rvar{y}^{-1}(\set{B})\rpa
  \quad \forall \set{A} \in \sset{F},\,\set{B} \in \sset{G}.
\end{equation}
The joint probability is related to $\prob{\rvar{x}}$ and $\prob{\rvar{y}}$ by
\begin{equation}\label{eq:sum-rule-rvar}
  \prob{\rvar{x},\rvar{y}}(\set{A},\,\set{Y}) =
  \prob{\rvar{x}}(\set{A}),~
  \prob{\rvar{x},\rvar{y}}(\set{X},\,\set{B}) =
  \prob{\rvar{y}}(\set{B})
  \quad \forall \set{A} \in \sset{F},\,\set{B} \in \sset{G}.
\end{equation}
In this context $\prob{\rvar{x}}$ and $\prob{\rvar{y}}$ are referred to as \emph{marginal distributions} of the joint distribution. Two random variables $\rvar{x}$ and $\rvar{y}$ are said to be independent if and only if
\begin{equation}\label{eq:independent-rvars}
  \prob{\rvar{x},\,\rvar{y}}(\set{A},\set{B}) = \prob{\rvar{x}}(\set{A})\,\prob{\rvar{y}}(\set{B})
  \quad \forall \set{A} \in \sset{F},\,\set{B} \in \sset{G}.
\end{equation}
\marginpar{In Kolmogorov's probability theory, \eqref{eq:conditional-probability} is given as an additional definition distinct from the basic axioms. In alternatives such as the work of Cox \citep{cox1946probability,cox1963algebra} and de Finetti \citep{de1992foresight}, conditional probabilities are instead viewed as a primitive.}
A particularly key concept for inference is the definition of \emph{conditional probability}. The conditional probability of an event $\set{A} \in \sset{E}$ occurring given another event $\set{B} \in \sset{E}$ has occurred is denoted $\probability(\set{A} \gvn \set{B})$ and we have the definition
\begin{equation}\label{eq:conditional-probability}
  \probability(\set{A} \gvn \set{B}) =
  \frac{\probability(\set{A} \cap \set{B})}{\probability(\set{B})}
  \quad \forall \set{A} \in \sset{E},\,\set{B} \in \sset{E} : \probability(\set{B}) \neq 0.
\end{equation}
Correspondingly we denote the conditional probability of the event of the random variable $\rvar{x}$ taking a value in $\set{A} \in \sset{F}$ given the event that the random variable $\rvar{y}$ takes a value in $\set{B} \in \sset{G}$ as $\prob{\rvar{x}|\rvar{y}}(\set{A}\gvn\set{B})$. Using \eqref{eq:conditional-probability} and \eqref{eq:joint-probability-rvar}, $\prob{\rvar{x}|\rvar{y}}$ and $\prob{\rvar{y}|\rvar{x}}$ can be shown to satisfy
\begin{equation}\label{eq:product-rule}
\begin{split}
  \prob{\rvar{x},\rvar{y}}(\set{A},\,\set{B}) =
  \prob{\rvar{x}|\rvar{y}}(\set{A} \gvn \set{B}) \, \prob{\rvar{y}}(\set{B}) =
  \prob{\rvar{y}|\rvar{x}}(\set{B} \gvn \set{A}) \, \prob{\rvar{x}}(\set{A})\\
  \forall \set{A} \in \sset{F},\,\set{B} \in \sset{G}.
\end{split}
\end{equation}
This decomposition of a joint probability into a product of a conditional and marginal is sometimes referred to as the product rule. An implication of \eqref{eq:product-rule} is what is often termed \emph{Bayes' theorem}
\begin{equation}\label{eq:bayes-theorem}
\begin{split}
  \prob{\rvar{x}|\rvar{y}}(\set{A} \gvn \set{B}) =
  \frac
    {\prob{\rvar{y}|\rvar{x}}(\set{B} \gvn \set{A}) \, \prob{\rvar{x}}(\set{A})}
    {\prob{\rvar{y}}(\set{B})} 
  \quad
  \forall \set{A} \in \sset{F},\,
  \set{B} \in \sset{G} : \prob{\rvar{y}}(\set{B}) \neq 0,
\end{split}
\end{equation}
which will be of key importance in the later discussion of inference.

The definition in \eqref{eq:joint-probability-rvar} of the joint probability of a pair of random variables can be extended to arbitrarily large collections of random variables. Similarly conditional probabilities can be defined for collections of multiple jointly dependent random variables, with the product rule given in \eqref{eq:product-rule} generalising to a combinatorial number of possible factorisations of the joint probability. Graphical models offer a convenient way of representing the dependencies between large collections of random variables and any resulting factorisation structure in their joint probability, and are discussed in Section \ref{sec:graphical-models}.

\subsection{Probability densities}\label{subsec:probability-densities}

So far we have not specified how the probability measure $\probability$ is defined and by consequence the probability (distribution) of a random variable. 
\marginpar{A measure on $\set{X}$ is $\sigma$-finite if $\set{X}$ is a countable union of finite measure sets.}
The Radon--Nikodym theorem guarantees that for a pair of $\sigma-$finite measures $\mu$ and $\nu$ on a measurable space $(\set{X},\,\sset{F})$ where $\nu$ is absolutely continuous with respect to $\mu$,  then there is a unique (up to $\mu$-null sets) measurable function $f : \set{X} \to [0,\infty)$ termed a \emph{density} such that
\begin{equation}\label{eq:radon-nikodym}
  \nu(\set{A}) = \int_{\set{A}} f\,\dr\mu 
  = \int_{\set{A}} f(x) \, \mu(\dr x)
  \quad \forall \set{A} \in \sset{F}.
\end{equation}
\marginpar{If $\mu$ and $\nu$ are measures on a measurable space $(\set{X},\,\sset{F})$ then $\nu$ has absolute continuity \acs{WRT} to $\mu$ if $~\forall \set{A} \in \sset{F}$, \mbox{$\mu(\set{A})=0 \Rightarrow \nu(\set{A})=0$.}}
The two Lebesgue integral notations above are equivalent and we will use them interchangeably. The density function $f$ is also termed the \emph{Radon-Nikodym derivative} of $\nu$ with respect to $\mu$, denoted $\td{\nu}{\mu}$. Density functions therefore represent a convenient way to define a probability distribution with respect to a reference measure we will term the \emph{base measure}. The key requirement defining what is an appropriate base measure to use it that the probability measure of interest is absolutely continuous with respect to it.

It can also be shown that if $f = \td{\nu}{\mu}$ and  $g$ is a  measurable function
\begin{equation}\label{eq:integral-wrt-density}
  \int_{\set{X}} g(x)\,\nu(\dr x) = \int_{\set{X}} g(x)\, f(x)\,\mu(\dr x),
\end{equation}
which we will use later when discussing calculation of expectations.

\marginpar{The Lebesgue measure assigns a measure to subsets of a Euclidean space, and for $\reals$, $\reals^2$ and $\reals^3$ formalises the intuitive concepts of length, area and volume of subsets respectively.}
%$\lebm{1}(\set{E})$ of a subset $\set{E} \subseteq \reals$ is $\lebm{1}(\set{E}) = \inf\lbrace \sum_{i=1}^\infty (b_i - a_i) :$ $E \subseteq \cup_{i=1}^\infty [a_i,\,b_i],$ $a_i,b_i \in \reals, a_i \leq b_i ~\forall i\in\naturals\rbrace$.}
Real random variables will typically have a distribution $\prob{\rvar{x}}$ defined by a probability density $\pden{\rvar{x}} : \reals \to [0,\,\infty)$ with respect to the \emph{Lebesgue measure}, $\lebm{1}$, on $\reals$,
\begin{equation}\label{eq:real-rv-prob-dens}
    \prob{\rvar{x}}(\set{A})
    = \int_{\set{A}} \pden{\rvar{x}}(x) \,\lebm{1}(\dr x)
    = \int_{\set{A}} \pden{\rvar{x}}(x) \,\dr x
    \qquad
    \forall \set{A} \in \borel(\reals).
\end{equation}
Analogously for a random vector $\rvct{x}$ with density $\pden{\rvct{x}} : \reals^D \to [0,\,\infty)$ with respect to the $D$-dimensional Lebesgue measure $\lebm{D}$ we have that
\begin{equation}\label{eq:vector-prob-dens}
    \prob{\rvct{x}}(\set{A})
    = \int_{\set{A}} \pden{\rvct{x}}(\vct{x}) \,\lebm{D}(\dr \vct{x})
    = \int_{\set{A}} \pden{\rvct{x}}(\vct{x}) \,\dr \vct{x}
    \qquad
    \forall \set{A} \in \borel(\reals^D).
\end{equation}
%The normalisation requirement for the probability measure $\probability_{\rvar{x}}$ means that $\int_{\set{X}}\pden{\rvar{x}}\,\dr\lebm{1} = 1$. 
The notation in the second equalities in \eqref{eq:real-rv-prob-dens} and \eqref{eq:vector-prob-dens} uses a convention that will be used throughout this thesis that integrals without an explicit measure are with respect to the Lebesgue measure. 

\marginpar{The counting measure $\countm$ is defined as $\countm(\set{A}) = |\set{A}|$ for all finite $\set{A}$ and $\countm(\set{A}) = +\infty$ otherwise.}
The probability distribution of a discrete random variable can be defined via probability density $\pden{\rvar{x}} : \set{X} \to [0,\,1]$ with respect to the \emph{counting measure} $\countm$,
\begin{equation}
    \prob{\rvar{x}}(\set{A})
    = \int_{\set{A}} \pden{\rvar{x}}(x) \,\countm(\dr x)
    = \sum_{x \in \set{A}} \pden{\rvar{x}}(x) 
    \qquad
    \forall \set{A} \in \powerset(\set{X}).
\end{equation}
The co-domain of a probability density $\pden{\rvar{x}}$ for a discrete random variable is restricted to $[0,\,1]$ due to the non-negativity and normalisation requirements for the probability measure $\prob{\rvar{x}}$, with $\sum_{x\in\set{X}} \pden{\rvar{x}}(x) = 1$. Commonly for the case of a discrete random variable, the density $\pden{\rvar{x}}$ is instead referred to as a \emph{probability mass function}, with density reserved for real random variables. We will however use \emph{probability density} in both cases in keeping with the earlier definition of a density, this avoiding difficulties with terminology and notation when defining joint probabilities on a mixture of real and discrete random variables.

\marginpar{If $(\set{X}_1,\,\sset{F}_1,\,\mu_1)$ and $(\set{X}_2,\,\sset{F}_2,\,\mu_2)$ are two measure spaces, the product measure $\mu_1 \times \mu_2$ on a measurable space $(\set{X}_1\times\set{X}_2,\,\sset{F}_1\otimes\sset{F}_2)$ is defined as satisfying $(\mu_1\times\mu_2)(\set{A}_1\times\set{A}_2) = \mu_1(\set{A}_1)\mu_2(\set{A}_2)$ $\forall \set{A}_1\in\sset{F}_1,\,\set{A}_2\in\sset{F}_2$.}
The joint probability $\prob{\rvar{x},\rvar{y}}$ of a pair of random variables $\rvar{x}$ and $\rvar{y}$ with co-domains the measurable spaces $(\set{X},\,\sset{F})$ and $(\set{Y},\,\sset{G})$ respectively, can be defined via a joint probability density $\pden{\rvar{x},\rvar{y}} : \set{X} \times \set{Y} \to [0,\infty)$ with respect to a product measure $\mu_{\rvar{x},\rvar{y}} = \mu_{\rvar{x}} \times \mu_{\rvar{y}}$ by
\begin{equation}\label{eq:real-rv-joint-prob-dens}
  \prob{\rvar{x},\rvar{y}}(\set{A},\set{B}) =
  \int_{\set{A}\times\set{B}} 
    \pden{\rvar{x},\rvar{y}}(x,y)
  \,\mu_{\rvar{x},\rvar{y}}(\dr x, \dr y) 
\end{equation}
As a consequence of Fubini's theorem, the integral over $\mu_{\rvar{x},\rvar{y}}$ can be expressed as iterated integrals over $\mu_{\rvar{x}}$ and $\mu_{\rvar{y}}$
\begin{equation}
\begin{split}
  \prob{\rvar{x},\rvar{y}}(\set{A},\set{B})&=
  \int_{\set{A}} \int_{\set{B}}
    \pden{\rvar{x},\rvar{y}}(x,y)
  \,\mu_{\rvar{x}}(\dr x)\,\mu_{\rvar{y}}(\dr y)
  \\  
  &=
  \int_{\set{B}} \int_{\set{A}}
    \pden{\rvar{x},\rvar{y}}(x,y)
  \,\mu_{\rvar{y}}(\dr y)\,\mu_{\rvar{x}}(\dr x)
  \quad \forall \set{A} \in \sset{F}, \,\set{B} \in \sset{G}.
\end{split}
\end{equation}
The two measures $\mu_{\rvar{x}}$ and $\mu_{\rvar{y}}$ can differ for example $\mu_{\rvar{x}} = \lebm{1}$ and $\mu_{\rvar{y}} = \countm$ if $\rvar{x}$ is a real random variable and $\rvar{y}$ is a discrete random variable.

When dealing with random variables, we will often only specify the co-domain of the random variable(s) and a (joint) probability density, with the base measure being implicitly defined as the Lebesgue measure for real random variables (or vectors), counting measure for discrete random variables and an appropriate product measure for a mix of random variables. Similarly we will usually neglect to explicitly define the probability space $(\set{S},\,\sset{E},\,\probability)$ which the random variable(s) map from. In this case we will typically use the loose notation $\rvar{x} \in \set{X}$ to mean a random variable $\rvar{x}$ with co-domain $\set{X}$. 

%This less explicit but more succinct probability notation in terms of random variables and densities is common in the machine learning and computational statitistics literature and will generally be preferred to improve readability. 
%The underlying measure-theoretic basis of these concepts will however be important for some of the upcoming definitions in this chapter and some of the derivations later in the thesis. 
%\ref{tab:standard-distributions-discrete},
Tables \ref{tab:standard-distributions-unbounded} and \ref{tab:standard-distributions-bounded} in Appendix \ref{app:distribution-definitions} give definitions of the densities and shorthand notation for some common parametric probability distributions that we use in this thesis.

\subsection{Transforms of random variables}\label{subsec:change-of-variables}

A key concept we make use of in this thesis is defining transformations of random variables. Let $\rvar{x}$ be a random variable with co-domain the measurable space $(\set{X},\,\sset{F})$. Further let $(\set{Y},\,\sset{G})$ be a second measurable space and $\phi : \set{X} \to \set{Y}$ a measurable function between the two spaces. If we define $\rvar{y} = \phi \circ \rvar{x}$ then analogously to our original definition of $\prob{\rvar{x}}$ as the pushforward measure of $\probability$ under the measurable function defining $\rvar{x}$, we can define $\prob{\rvar{y}}$ in terms of $\prob{\rvar{x}}$ as
\begin{equation}\label{eq:change-of-variables-probability}
  \prob{\rvar{y}}(\set{A}) = 
  \prob{\rvar{x}} \circ \phi^{-1}(\set{A}) =
  \prob{\rvar{x}}\lpa \lbrace x \in \set{X} : \phi(x) \in \set{A} \rbrace \rpa
  \quad \forall \set{A} \in \sset{G},
\end{equation}
i.e. the probability of the event $\rvar{y} \in \set{A}$ is equal to the probability of $\rvar{x}$ taking a value in the pre-image under $\phi$ of $\set{A}$. To calculate probabilities of transformed random variables therefore we will therefore need to be able to find the pre-images of sets under the transformation.

If the distribution $\prob{\rvar{x}}$ is defined by a density $\pden{\rvar{x}}$ with respect to a measure $\mu_{\rvar{x}}$, we can also in some cases find a density $\pden{\rvar{y}}$ on the transformed variable $\rvar{y} = \phi(\rvar{x})$ with respect to a (potentially different) measure $\mu_{\rvar{y}}$
\begin{equation}\label{eq:change-of-variables-general}
  \prob{\rvar{y}}(\set{A}) =
  \int_{\phi^{-1}(\set{A})} \pden{\rvar{x}}(x) \,\mu_{\rvar{x}}(\dr x) = 
  \int_{\set{A}} \pden{\rvar{y}}(y) \,\mu_{\rvar{y}}(\dr y)
  \quad \forall \set{A} \in \sset{G}.
\end{equation}

For random variables with countable co-domains where the integral in \eqref{eq:change-of-variables-general} corresponds to a sum, a $\pden{\rvar{y}}$ satisfying \eqref{eq:change-of-variables-general} is simple to identify. If $\rvar{x}$ is a discrete random variable with probability density $\pden{\rvar{x}}$ with respect to the counting measure, then $\rvar{y} = \phi(\rvar{x})$ will necessarily also be a discrete random variable. Applying \eqref{eq:change-of-variables-general} for $\pden{\rvar{x}} = \td{\prob{\rvar{x}}}{\countm}$ we have that\footnote{We use $\phi^{-1}(y)$ as a shorthand here for $\phi^{-1}(\lbrace y \rbrace)$ i.e. the pre-image of a singleton set $\fset{y}$ under $\phi$ or equivalently the \emph{fibre} of an element $y$ under $\phi$. In cases where an inverse function exists we will also use the same notation, which of the three meanings is intended should be clear from the context.} 
\begin{align}\label{eq:change-of-variables-discrete-derivation}
  \int_{\phi^{-1}(\set{A})} \pden{\rvar{x}}(x) \,\countm(\dr x) &= 
  \sum_{x\in\phi^{-1}(\set{A})} \pden{\rvar{x}}(x)  =
  \sum_{y \in \set{A}} \sum_{x\in\phi^{-1}(y)} \pden{\rvar{x}}(x) \nonumber \\
  &= \int_{\set{A}} \sum_{x\in\phi^{-1}(y)} \pden{\rvar{x}}(x) \,\countm(\dr y)
  \quad \forall \set{A} \in \sset{G}.
\end{align}
We can therefore define $\pden{\rvar{y}} = \td{\prob{\rvar{y}}}{\countm}$ in terms of $\pden{\rvar{x}}$ as
\begin{equation}\label{eq:change-of-variables-discrete}
  \pden{\rvar{y}}(y) = \sum_{x \in \phi^{-1}(y)} \pden{\rvar{x}}(x)
  \quad \forall y \in \set{Y}.
\end{equation}
In the special case that $\phi$ is bijective with an inverse $\phi^{-1}$ we have that 
\begin{equation}\label{eq:change-of-variables-discrete-bijective}
  \pden{\rvar{y}}(y) = \pden{\rvar{x}}\circ\phi^{-1}(y)
  \quad \forall y \in \set{Y}.
\end{equation}
For transformations of real random variables and vectors, the situation is more complicated as we need to account for any local contraction or expansion of space by the transformation. We will consider here the special case where the transformation is a \emph{diffeomorphism}: a differentiable bijection which has an inverse which is also differentiable. In Chapter \ref{ch:differentiable-generative-models} we will consider how this can be generalised to non-bijective differentiable functions, including the case where the dimensionalities of the domain and co-domain of the function differ.

Let $\set{X} \subseteq \reals^N$ and $\set{Y} \subseteq \reals^N$ and $\vct{\phi} : \set{X} \to \set{Y}$ be a diffeomorphism. Then the \emph{Jacobian} of $\vct{\phi}$ is defined as
\begin{equation}
  \jacob{\vct{\phi}}{\vct{x}} = \pd{\vct{\phi}}{\vct{x}} =
  \begin{bmatrix}
    \pd{\phi_1}{x_1} & \cdots & \pd{\phi_1}{x_N}\\
    \vdots & \ddots & \vdots \\
    \pd{\phi_N}{x_1} & \cdots & \pd{\phi_N}{x_N}
  \end{bmatrix}.
\end{equation}
The Jacobian matrix describes the local transformation of an infinitesimal volume element $\dr\vct{x}$ in $\set{X}$ under the map $\vct{\phi}$. In particular the corresponding volume element in $\set{Y}$ under the map will be an infinitesimal parallelotope spanned by the columns of the Jacobian $\jacob{\vct{\phi}}{\vct{x}}$. The Jacobian matrix determinant $\left|\,\jacob{\vct{\phi}}{\vct{x}}\right|$ which corresponds to the volume of this parallelotope therefore determines hows the volume elements scales under the map - a value more than one corresponds to a local expansion and less than one to a contraction. Informally we therefore have that $\dr\vct{y} = \left|\,\jacob{\vct{\phi}}{\vct{x}}\right|\,\dr\vct{x}$ and applying the same arguments to the inverse map $\vct{\phi}^{-1}$, $\dr\vct{x} = \left|\,\jacob{\vct{\phi}^{-1}}{\vct{y}}\right|\,\dr\vct{y}$.

Let $\rvct{x}$ be a random vector taking values in the measurable space $(\set{X},\,\borel(\set{X}))$ and define $\rvct{y} = \vct{\phi} \circ \rvct{x}$ as a random vector taking values in  $(\set{Y},\,\borel(\set{Y}))$. If $\prob{\rvct{x}}$ has a density $\pden{\rvct{x}}$ with respect to the Lebesgue measure %then we have that
\begin{equation}
\begin{split}
  \prob{\rvct{y}}(\set{A}) = \prob{\rvct{x}}\circ\vct{\phi}^{-1}(\set{A})
  &= \int_{\vct{\phi}^{-1}(\set{A})}\kern-2pt\pden{\rvct{x}}(\vct{x})\,\dr\vct{x}\\
  &= \int_{\set{A}} \pden{\rvct{x}}\circ\vct{\phi}^{-1}(\vct{y}) \,\left|\,\jacob{\vct{\phi}^{-1}}{\vct{y}}\right|\,\dr\vct{y}.
\end{split}
\end{equation}
Therefore $\prob{\rvct{y}}$ has a density $\pden{\rvct{y}}$ with respect to the Lebesgue measure 
\begin{equation}\label{eq:change-of-variables-vector-bijective}
  \pden{\rvct{y}}(\vct{y}) = 
    \pden{\rvct{x}}\circ\vct{\phi}^{-1}(\vct{y})\,
    \left|\,\jacob{\vct{\phi}^{-1}}{\vct{y}}\right|
  \quad \forall \vct{y} \in \set{Y}.
\end{equation}
In both the cases considered, we have seen that if the function $\phi$ the random variable $\rvar{x}$ is mapped through is bijective, it is tractable to compute a density on the mapped random variable $\rvar{y}$ as the pre-image $\phi^{-1}(y)$ of a point $y \in \set{Y}$ is itself a point. Bijectivity is a very limiting condition however, with many models involving non-bijective transformations of random variables. In Chapter \ref{ch:differentiable-generative-models} we will discuss methods for performing inference in generative models defined by complex, non-dimension preserving and non-bijective transformations of random variables.

\subsection{Expectations}\label{subsec:expectations}

A key operation when working with probabilistic models is computing expectations. Let $(\set{S},\,\sset{E},\,\probability)$ be a probability space, and $\rvar{x} : \set{S} \to \set{X}$ a random variable on this space. The \emph{expected value of $\rvar{x}$} is defined as
\begin{equation}\label{eq:expectation-general}
  \expc{\rvar{x}} = \int_{\set{S}} \rvar{x}\,\dr\probability.
\end{equation}
Usually it will be more convenient to express expectations in terms of the probability $\prob{\rvar{x}}$. If $g : \set{X} \to \reals$ is an integrable function then
\begin{equation}\label{eq:integral-wrt-pushforward-measure}
  \int_{\set{X}} g(x) \,\prob{\rvar{x}}(\dr x) =
  \int_{\set{S}} g \circ \rvar{x}(s) \,\probability(\dr s).
\end{equation}
If we take $g$ as the identity map we therefore have that
\begin{equation}\label{eq:expectation-pushfoward}
  \expc{\rvar{x}} = \int_{\set{X}} x \,\prob{\rvar{x}}(\dr x).
\end{equation}
If $\probability_{\rvar{x}}$ is given by a density $\pden{\rvar{x}} = \td{\prob{\rvar{x}}}{\mu}$ then using \eqref{eq:integral-wrt-density} we also have
\begin{equation}\label{eq:expectation-density}
  \expc{\rvar{x}} = \int_{\set{X}} x \,\pden{\rvar{x}}(x) \,\mu(\dr x).
\end{equation} %which is often the form used for computation.
A further useful implication of \eqref{eq:integral-wrt-pushforward-measure} is what is sometimes termed the \emph{Law of the unconscious statistician}. Let $\rvar{x} : \set{S} \to \set{X}$ be a random variable, $\phi : \set{X} \to \set{Y}$ a measurable function and define $\rvar{y} = \phi \circ \rvar{x}$. Then %the expected value of $\rvar{y}$ is
\begin{equation}\label{eq:law-of-the-unconscious-statistician}
  \expc{\rvar{y}} = \int_{\set{S}} \rvar{y}(s) \,\probability(\dr s)
  = \int_{\set{S}} \phi \circ \rvar{x}(s) \,\probability(\dr s)
  = \int_{\set{X}} \phi(x) \,\prob{\rvar{x}}(\dr x),
\end{equation}
i.e. it can be calculated by integrating $\phi$ with respect to $\prob{\rvar{x}}$. This means we can calculate the expected value of a transformed random variable $\rvar{y} = \phi(\rvar{x})$ without needing to use the change of variables formulae from Section \ref{subsec:change-of-variables} to explicitly calculate the probability $\prob{\rvar{y}}$ (or density $\pden{\rvar{y}}$) and with a relatively weak condition of measurability on $\phi$.

Closely related to the expected value are the \emph{variance} and \emph{covariance} of a random variable. The variance of a random variable $\rvar{x}$ is defined
\begin{equation}\label{eq:variance-definition}
  \var{\rvar{x}} = \expc{(\rvar{x} - \expc{\rvar{x}})^2} = \expc{\rvar{x}^2} - \expc{\rvar{x}}^2.
\end{equation}
For a pair of random variables $\rvar{x}$ and $\rvar{y}$ their covariance is defined 
\begin{equation}\label{eq:covvariance-definition}
  \cov{\rvar{x}, \rvar{y}} = \expc{(\rvar{x} - \expc{\rvar{x}})(\rvar{y} - \expc{\rvar{y}})}.
\end{equation}

\subsection{Conditional expectations and densities}

A related concept, and one which will be key to the discussion of inference, is conditional expectation. Let $(\set{S},\,\sset{E},\,\probability)$ be a probability space, $(\set{X},\,\sset{F})$ and $(\set{Y},\,\sset{G})$ two measurable spaces and $\rvar{x} : \set{S} \to \set{X}$ and $\rvar{y} : \set{S} \to \set{Y}$ two random variables. Then the \emph{conditional expectation of $\rvar{x}$ given $\rvar{y}$}, is defined as a measurable function $\expc{\rvar{x}\gvn\rvar{y}} : \set{Y} \to \set{X}$ satisfying
\begin{equation}\label{eq:conditional-expectation-property}
  \int_{\rvar{y}^{-1}(\set{B})} \rvar{x}(s) \,\probability(\dr s) =
  \int_{\set{B}} \expc{\rvar{x}\gvn\rvar{y}}(y) \,\prob{\rvar{y}}(\dr y)
  \quad \forall \set{B} \in \sset{G}.
\end{equation}
$\expc{\rvar{x}\gvn\rvar{y}}$ is guaranteed to be uniquely defined almost everywhere in $\set{Y}$ by \eqref{eq:conditional-expectation-property}, i.e. up to $\prob{\rvar{y}}$-null sets. As a particular case where $\set{B} = \set{Y}$ we recover what is sometimes termed the \emph{Law of total expectation}
\begin{equation}\label{eq:law-of-total-expectation}
  \int_{\set{S}} \rvar{x} \,\dr\probability =
  \int_{\set{S}} \expc{\rvar{x}\gvn\rvar{y}} \circ \rvar{y} \,\dr\probability
   \implies
  \expc{\rvar{x}} =
  \expc{\expc{\rvar{x}\gvn\rvar{y}}\circ\rvar{y}}.
\end{equation}
We will also use a more standard notation for the conditional expectation evaluated at point $\expc{\rvar{x}\gvn\rvar{y} = y} \equiv \expc{\rvar{x}\gvn\rvar{y}}(y)$ but use the latter in this section to stress its definition as a measurable function.

Conditional expectation can be used to define the \emph{regular conditional distribution} of a random variable conditioned on another random variable taking a particular value
\begin{equation}\label{eq:regular-conditional-probability}
  \prob{\rvar{x}|\rvar{y}}(\set{A} \gvn y) = \expc{\ind{\set{A}}\circ\,\rvar{x} \gvn \rvar{y}}(y)
  \quad\forall y \in \set{Y},\,\set{A} \in \sset{F}.
\end{equation}
We have reused our notation for conditional probability of random variables from Section \ref{subsec:joint-and-conditional-probabilities} here, however it should be clear from whether the value conditioned on is a point or a set which is being referred to. A regular conditional distribution $\prob{\rvar{x}|\rvar{y}}(\cdot\gvn y)$ defines a valid probability measure on $(\set{X},\sset{F})$ for $\prob{\rvar{y}}$-almost all $y$ and using \eqref{eq:conditional-expectation-property} we have
\begin{equation}\label{eq:regular-conditional-probability-joint-relationship}
  \prob{\rvar{x},\rvar{y}}(\set{A},\set{B}) =
  \int_{\set{B}} \prob{\rvar{x}|\rvar{y}}(\set{A}\gvn y) \,\prob{\rvar{y}}(\dr y)
  \qquad \forall \set{A} \in \sset{F},\,\set{B} \in \sset{G}.
\end{equation}
We can use this relationship to also motivate a definition of conditional density. We require that a joint density $\pden{\rvar{x},\rvar{y}} = \td{\prob{\rvar{x},\rvar{y}}}{(\mu_{\rvar{x}}\times\mu_{\rvar{y}})}$ exists and has marginal density $\pden{\rvar{y}} = \td{\prob{\rvar{y}}}{\mu_{\rvar{y}}}$. Then for all $\set{A} \in \sset{F}$, $\set{B} \in \sset{G}$
\begin{equation}\label{eq:conditional-density-derivation-1}
  \int_{\set{B}} \prob{\rvar{x}|\rvar{y}}(\set{A}\gvn y) \,\prob{\rvar{y}}(\dr y)
  =
  \int_{\set{B}}\int_{\set{A}} 
    \pden{\rvar{x},\rvar{y}}(x,y)
  \,\mu_{\rvar{x}}(\dr x)\,\mu_{\rvar{y}}(\dr y)
\end{equation}
If we define the \emph{conditional density} $\pden{\rvar{x}|\rvar{y}}$ as
\begin{equation}\label{eq:conditional-density-definition}
  \pden{\rvar{x}|\rvar{y}}(x\gvn y) =
  \begin{cases}
    \frac{\pden{\rvar{x},\rvar{y}}(x,y)}{\pden{\rvar{y}}(y)} 
    &\qquad \forall x\in\set{X},\, y \in \set{Y} : \pden{\rvar{y}}(y) > 0\\
    0
    &\qquad \forall x\in\set{X},\,y \in \set{Y} : \pden{\rvar{y}}(y) = 0
  \end{cases}
\end{equation}
then substituting this definition in to \eqref{eq:conditional-density-derivation-1} we have
\begin{equation}\label{eq:conditional-density-derivation-2}
  \int_{\set{B}} \prob{\rvar{x}|\rvar{y}}(\set{A}\gvn y) \,\prob{\rvar{y}}(\dr y)
  =
  \int_{\set{B}}\int_{\set{A}} 
    \pden{\rvar{x}|\rvar{y}}(x\gvn y)
  \,\mu_{\rvar{x}}(\dr x)\,\prob{\rvar{y}}(\dr y).
\end{equation}
Therefore $\pden{\rvar{x}|\rvar{y}}$ is the density of the regular conditional distribution $\prob{\rvar{x}|\rvar{y}}$. We also have that if $\pden{\rvar{x},\rvar{y}}$ and $\pden{\rvar{y}}$ can be defined that 
\begin{equation}\label{eq:conditional-expectation-density}
  \expc{\rvar{x}\gvn\rvar{y}}(y) =
  \int_{\set{X}} x\,\pden{\rvar{x}|\rvar{y}}(x\gvn y) \,\mu_{\rvar{x}}(\dr x)
  \quad \forall y \in \set{Y} : \pden{\rvar{y}}(y) > 0.
\end{equation}
Note that the initial definition of conditional expectation in \eqref{eq:conditional-expectation-property} was not dependent on a joint density $\pden{\rvar{x},\rvar{y}}$ being defined. %available and so is more general than \eqref{eq:conditional-expectation-density}.

% reverse mode-automatic differentiation
% reparametrisation
% partial reparameterisation

\section{Graphical models}\label{sec:graphical-models}

\marginpar{Graphical models = statistics Ã— graph theory Ã— computer science\\---Zoubin Ghahramani}
When working with probabilistic models involving large numbers of random variables, it will often be the case that not all the variables are jointly dependent on each other but that instead there are more local  relationships between them. Graphical models, which use graphs to describe the dependencies between random variables, are a useful framework for visualising the structure of complex models.
% and for giving a graph-theoretic basis for establishing the dependence between sets of random variables. Central to graphical models is the concept of conditional independence. Let $\rvar{x} : \set{S} \to \set{X}$, $\rvar{y} : \set{S} \to \set{Y}$ and $\rvar{z} : \set{S} \to \set{Z}$ be three random variables with corresponding $\sigma$-algebras, $\sset{F}_{\rvar{x}}$, $\sset{F}_{\rvar{y}}$ and $\sset{F}_{\rvar{z}}$ respectively. Following from our earlier definition of (unconditional) independence of random variables in \eqref{eq:independent-rvars}, we say that \emph{$\rvar{x}$ and $\rvar{y}$ are conditionally independent given $\rvar{z}$}, denoted $\rvar{x} \perp \rvar{y} \gvn \rvar{z}$, if for $\prob{\rvar{z}}$-almost all $z \in \set{Z}$
%\begin{equation}\label{eq:conditional-independence-property}
%  \prob{\rvar{x},\rvar{y}|\rvar{z}}(\set{A},\set{B} \gvn z) =
%  \prob{\rvar{x}|\rvar{z}}(\set{A} \gvn z)\,
%  \prob{\rvar{y}|\rvar{z}}(\set{B} \gvn z)
%  ~\,\forall 
%  \set{A} \in \sset{F}_{\rvar{x}},\,
%  \set{B} \in \sset{F}_{\rvar{y}}.
%\end{equation}
%If a joint density on the random variables exists, a sufficient condition for $\rvar{x} \perp \rvar{y} \gvn \rvar{z}$ is that the conditional density $\pden{\rvar{x},\rvar{y}|\rvar{z}}$ factorises as
%\begin{equation}\label{eq:conditional-independence-densities}
%  \pden{\rvar{x},\rvar{y}|\rvar{z}}(x,y \gvn z) =
%  \pden{\rvar{x}|\rvar{z}}(x \gvn z)
%  \pden{\rvar{y}|\rvar{z}}(y \gvn z)
%  \quad \forall 
%  x \in \set{X},\,
%  y \in \set{Y},\,
%  z \in \set{Z}.
%\end{equation}
%This definition can be naturally extended to conditional independence when conditioning on more than one random variable, for example
%\begin{equation}\label{eq:conditional-independence-many-vars}
%  \rvar{v} \perp \rvar{x} \gvn \rvar{y},\,\rvar{z} \implies
%  \pden{\rvar{v},\rvar{x}|\rvar{y},\rvar{z}}(v,x \gvn y,z) =
%  \pden{\rvar{v}|\rvar{y},\rvar{z}}(v \gvn y,z)
%  \pden{\rvar{x}|\rvar{y},\rvar{z}}(x \gvn y,z).
%\end{equation}

Several graphical formalisms for representing dependency structure in probabilistic models have been proposed, with \emph{directed graphical models} \citep{pearl1988probabilistic} (also known as \emph{Bayesian networks}) and \emph{undirected graphical models} \citep{kindermann1980markov} (also known as \emph{Markov random fields}) both common in practice and each offering a more natural representation for certain model classes. In this thesis we will instead use \emph{factor graphs} \citep{frey1997factor,frey2002extending} which combine the representational abilities of both directed and undirected graphical models while also offering a richer framework for representing fine-grained information about model structure.

\begin{figure}[t]
\centering
\begin{subfigure}[b]{.45\linewidth}
\vskip 0pt
\centering
\includetikz{directed-factor-graph}
%\vskip 5pt
\caption{Example directed factor graph.}
\label{sfig:example-directed-factor-graph}
\end{subfigure}%
 \hspace*{\fill}
\begin{subfigure}[b]{.5\linewidth}
\vskip 0pt
\centering
\includetikz{undirected-factor-graph}
%\vskip 5pt
\caption{Example undirected factor graph.}
\label{sfig:example-undirected-factor-graph}
\end{subfigure}%
\caption[Factor graph examples.]{Examples of simple directed and undirected factor graphs. Square black nodes correspond to individual factors depending on the connected variables represented by circular nodes in the joint density.}
\label{fig:example-factor-graphs}
\end{figure}

Factor graphs are bipartite graphs consisting of two node types: \emph{variable nodes}, displayed as labelled circles and representing individual (potentially non-scalar) random variables in a probabilistic model, and \emph{factor nodes}, displayed as filled squares and representing individual factors in the joint density across the random variables in the model. Edges between nodes in a factor graph are always between nodes of disparate types i.e. between factor and variable nodes, but never between factor and factor or variable and variable nodes.

%\footnote{In the original extension of undirected factor graphs \citep{frey1997factor} to include directivity \citep{frey2002extending}, it was proposed to allow multiple directed factors to connect via directed edges to the same variable node, representing multiple factors in a conditional density on that varaiable. This generalisation introduces extra normalisation requirements and looses the interpretation of a directed factor as directly representing a conditional density, and so we will here only use directed factor graphs in which there is at most one directed edge connecting from a factor to a node.}
Factors may be either directed or undirected. Undirected factors, denoted by factor nodes in which all edges connecting to variable nodes are undirected, correspond to a factor in the joint density which depends on all of the variables with nodes connected to the factor, but without any requirement that the factor corresponds to a conditional or marginal probability density. 

Directed factors, factor nodes in which at least one edge from the factor node to a variable node is directed, correspond to a conditional density on the variables pointed to by directed edges given the values of the variables connected to the the factor node by undirected edges. If there are no undirected edges then the factor instead corresponds to a marginal density. Graphs with directed factors must not contain any directed cycles, i.e. connected loops of edges in which one of every pair of edges connected to a factor on the loop is directed and all of the directed edges point in the same sense around the loop. 

Figure \ref{sfig:example-directed-factor-graph} shows a simple example of fully directed factor graph for three random variables. The graph implies that the joint density for the model can be factorised as
\begin{equation}\label{eq:example-directed-graphical-model-factorisation}
  \pden{\rvar{x}_1,\rvar{x}_2,\rvar{x}_3}(x_1,x_2,x_3) = 
  \pden{\rvar{x}_3|\rvar{x}_1,\rvar{x}_2}(x_3 \gvn x_1,x_2) \,
  \pden{\rvar{x}_1}(x_1) \, \pden{\rvar{x}_2}(x_2).
\end{equation}
Figure \ref{sfig:example-undirected-factor-graph} shows a fully undirected factor graph on three random variables. If $\psi_{i,j}$ denotes the unnormalised density factor on the pair $(\rvar{x}_i,\,\rvar{x}_j)$ then the graph implies the joint density can be factorised as
\begin{equation}\label{eq:example-undirected-factor-graph-factorisation}
\begin{split}
  \pden{\rvar{x}_1,\rvar{x}_2,\rvar{x}_3}(x_1,x_2,x_3) =
  \frac{1}{Z} 
  \psi_{1,2}(x_1,x_2)
  \psi_{1,3}(x_1,x_3)
  \psi_{2,3}(x_2,x_3)
\end{split}
\end{equation}
with $Z$ a normalising constant such that the density integrates to one.

%Whether two variables are conditionally independent given a set of other variables can be checked from a factor graph by checking if all paths (i.e. connected series of edges and nodes) between the two corresponding variables nodes in the factor graph are \emph{blocked}. A path is blocked if at least one of the following conditions is satisfied \citep{frey2002extending}
%\begin{enumerate}
%  \item One of the variable nodes in the path is in the conditioning set.
%  \item One of the directed factor nodes in the path has two connected undirected edges in the path and there is no second directed path from the node to a variable node in the conditioning set.
%\end{enumerate}

%\begin{figure}[!t]
%\vskip 0pt
%\centering
%\includetikz{boltzmann-machine-factor-graph}
%%\vskip 5pt
%\caption[Boltzmann machine factor graph.]{Five unit Boltzmann machine factor graph showing explicit factorisation of distribution into pairwise and single variable potentials.}
%\label{fig:boltzmann-machine-factor-graph}
%\end{figure}
%
%As well as allowing representations of mixed graphs with both directed and undirected factors which cannot be represented with either directed or undirected graphical models, factor graphs are also able to include finer-grained information about the factorisation of the joint density than either of the other two model types by explicitly indicating the presence of individual factors. For instance Figure \ref{fig:boltzmann-machine-factor-graph} shows the factor graph for a \emph{Boltzmann machine} distribution, sometimes called a \emph{pairwise binary Markov random field} or \emph{Ising model}, on five binary random variables $\lbrace \rvar{s}_i \rbrace_{i=1}^5$. A Boltzmann machine distribution can be factored in to a product of pairwise weighted interactions $\exp(\rvar{s}_i W_{ij} \rvar{s}_j)$ and single variable bias potentials $\exp(b_i \rvar{s}_i)$, each of which are explicitly represented by labelled factors in Figure \ref{fig:boltzmann-machine-factor-graph}. A corresponding undirected graphical model representation would have a single clique involving all five variables, and so would not indicate any information about the factorisation of the joint density.

\begin{figure}[!t]
\vskip 0pt
\centering
\includetikz{radon-hierarchical-linear-regression-factor-graph}
%\vskip 5pt
\caption[Hierarchical linear regression model factor graph.]{Hierarchical linear regression model factor graph showing examples of extended factor graph notation.}% including deterministic factor nodes (\tikz{\node[op] {};}), shading to indicate observed variables, plate notation (rounded rectangle) and constant nodes ($\vct{x}^{(i)}$ and $c^{(i)}$).}
\label{fig:hier-lin-regression-factor-graph}
\end{figure}

Figure \ref{fig:hier-lin-regression-factor-graph} shows examples of some additional useful factor graph notation we will use in this thesis. We use as an example a factor graph corresponding to a hierarchical linear regression model which will be discussed in Chapter \ref{ch:continuous-tempering}. % The exact meaning of the model and its various factors are unimportant to the discussion of notation here so will be skipped for now. %We give some brief details now so the subsequent discussion of the notation used in Figure \ref{fig:hier-lin-regression-factor-graph} makes sense. The model is for a data set of $N$ real valued output values $\lbr y^{(i)} \rbr_{i=1}^N$ which are assumed to be \ac{IID} given $N$ corresponding input value pairs $\lbr (\vct{x}^{(i)},\,c^{(i)}) \rbr_{i=1}^N$ where each $\vct{x}^{(i)} \in \reals^D$ is a $D$-dimensional vector of real valued regressors, and each $c^{(i)} \in \fset{1\dots K}$ is an integer representation of a categorical regressor. A linear input-output relationship is assumed with 

It will often be useful to be able to explicitly represent deterministic functions applied to the random variables in a factor graph. For this purpose we introduce an additional node type denoted by an unfilled diamond (\tikzset{external/export next=false}\tikz{\node[op] {};}). The semantics of this node type are similar to standard directed factor nodes. Variables acting as inputs to the function are connected to the node by undirected edges and the variable corresponding to the function output indicated by a directed edge from the node to the relevant variable. Like standard factor nodes, the deterministic factor nodes only ever connect to variable nodes. The operations performed by the function on the inputs will usually be included as a label adjacent to the node as illustrated by the example in Figure \ref{fig:hier-lin-regression-factor-graph}. A deterministic factor node can informally\footnote{A Dirac delta is not strictly a density as it is not the Radon--Nikodym derivative of an absolutely continuous measure, however informally we treat is as the density of a singular Dirac measure with respect to the Lebesgue measure $\int f(x) \,\delta(\dr x) \simeq \int f(x) \delta(x) \,\dr x$.} be considered equivalent to a directed factor node with a degenerate Dirac delta conditional density on the output variable which concentrates all the probability mass at the output of the function applied to the inputs variables. %The previously discussed rules for evaluating conditional independency properties in factor graphs can be directly extended to account for the new node type by just considering it as a directed factor node.

The deterministic node notation allows generative models consisting of complex compositions of deterministic functions and probabilistic sampling operations to be represented in a unified framework. subgraphs of a directed factor graph consisting entirely of deterministic nodes can be viewed as \emph{computation graphs}, a graphical formalism typically used in numerical computing frameworks to support efficient \emph{automatic differentiation} algorithms. We exploit this idea in later in the thesis to allow propagation of derivatives through complex probabilistic models and make extensive use of automatic differentiation implementations in frameworks such as \emph{Theano} \citep{theano2016theano} in numerical experiments. In Appendix \ref{ch:computation-graphs} we provide a short review of the basic concepts of computation graphs and automatic differentiation and a discussion of their links to directed factor graphs.

In some cases constant values used in a model will be included in a factor graph as plain nodes indicated only by a label. The $\vct{x}^{(i)}$ and $c^{(i)}$ nodes in Figure \ref{fig:hier-lin-regression-factor-graph} are an example of this notation.

A commonly used convention in factor graphs is \emph{plate notation} \citep{buntine1994operations}, with an example of a plate shown by the rounded rectangle bounding some of the nodes in Figure \ref{fig:hier-lin-regression-factor-graph}. Plates are used to indicate a subgraph in the model which is replicated multiple times (with the replications being indexed over a set which is typically indicated in the lower right corner of the plate as in Figure \ref{fig:hier-lin-regression-factor-graph}). The subgraph entirely contained on the plate is assumed to be replicated the relevant number of times, with any edges crossing into the plate from variable nodes outside of the plate being repeated once for each subgraph replication. %Plates are commonly used to represent a model component repeated across multiple data items.

Each of the factors in Figure \ref{fig:hier-lin-regression-factor-graph} is labelled with a shorthand for a probability density function corresponding to the conditional or marginal density factor associated with the node. Definitions for the shorthand notations that are used for densities in this thesis are given in Appendix \ref{app:distribution-definitions}. The dependence of the factors on the value of the random variable the density is defined on is omitted in the labels for brevity.

A final additional notation used in Figure \ref{fig:hier-lin-regression-factor-graph} is the use of a shaded variable node (corresponding to $\rvar{y}^{(i)}$) to indicate a random variable corresponding to an observed quantity in the model.

\newpage

\section{Inference}

\begin{figure}	
\centering
\includetikz{simple-iid-factor-graph}
\caption[Factor graph of \acs{IID} observed variables.]{Factor graph of $N$ observations $\rvct{y}^{(n)}$ independently and identically distributed according to a distribution with parameters $\rvct{x}$.}
\label{fig:simple-iid-factor-graph}
\end{figure}

Having now introduced the tools and notation we use to define probabilistic models, we will now describe the inference problems we consider approximate approaches to solving in this thesis. We begin with a overview of \emph{Bayesian inference}.

%We begin by motivating our earlier statement that they key computational challenge in inference problems is the computation of high-dimensional integrals.

%We begin with a brief review of the \emph{Bayesian inference} approach.

\marginpar{You cannot do inference without making assumptions\\---David Mackay}
The starting point for any inference problem is to define a model specifying proposed relationships between the observed data and unknown quantities to be inferred. The model codifies the assumptions we make about the problem and any prior beliefs we have. In virtually all real inference problems the model will be a simplified description of a much more complex underlying process, usually motivated by prior empirical observations that the behaviour proposed by the model is a reasonable description of reality. For now we will consider the model as a singular fixed object we will perform inference with. We consider probabilistic model comparison in a subsequent subsection.

Amongst the simplest, but also most common, modelling assumptions made is that the observed data values are \ac{IID} according to a parametric probability distribution. If we denote the collection of $N$ observed variables $\lbrace \rvct{y}^{(n)} \rbrace_{n=1}^N$ then we assume that each is independently generated from a distribution $\prob{\rvct{y}^{(n)}|\rvct{x}} = \prob{\rvct{y}|\rvct{x}} ~\forall n \in \lbrace 1 \,...\,N\rbrace$ with density $\pden{\rvct{y}|\rvct{x}} = \pd{\prob{\rvct{y}|\rvct{x}}}{\mu_{\rvct{y}}}$ and governed by a set of unknown parameters $\rvct{x} \in \set{X}$. %The \ac{IID} assumption is widely made in inference problems and although it will not be always be entirely valid in practice, it will often be a reasonable approximation. %A particularly common application is in probabilistic classification and regression problems where the observed variables $\lbrace \rvct{y}^{(n)} \rbrace_{n=1}^N$ represent the target

Any beliefs we have about the plausible values for the parameters prior to observing data are integrated into the model by choosing an appropriate, typically parametric, marginal distribution $\prob{\rvct{x}}$, with this distribution, and the corresponding density $\pden{\rvct{x}} = \pd{\prob{\rvct{x}}}{\mu_{\rvct{x}}}$, referred to as the \emph{prior}. The joint distribution on the model variables then factorises as
\begin{equation}\label{eq:iid-data-joint-density-factorisation}
  \pden{\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)},\,\rvct{x}}(\vct{y}^{(1)},\,...\,,\vct{y}^{(N)},\,\vct{x}) =
  \prod_{n=1}^N \pden{\rvct{y}|\rvct{x}}(\vct{y}^{(n)}\gvn\vct{x})\,
  \pden{\rvct{x}}(\vct{x})
\end{equation}
with this structure illustrated as a directed factor graph in Figure \ref{fig:simple-iid-factor-graph}. In analogy to the naming of the prior, the conditional distribution on the unknown model parameters after conditioning on observed data values is termed the \emph{posterior} and from the definition of conditional density \eqref{eq:conditional-density-definition} we can express its density as
\begin{equation}\label{eq:iid-data-posterior-density}
  \pden{\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{x} \gvn \vct{y}^{(1)},\,...\,,\vct{y}^{(N)}) =
\frac{
  \prod_{n=1}^N \pden{\rvct{y}|\rvct{x}}(\vct{y}^{(n)}\gvn\vct{x})\,
  \pden{\rvct{x}}(\vct{x})
}
{
 \pden{\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{y}^{(1)},\,...\,,\vct{y}^{(N)})
}.
\end{equation}
\marginpar{Bayesian inference is named after Thomas Bayes,~an~18th~century Presbyterian~minister, who proved a special case of what is now termed~Bayes'~theorem. Pierre-Simon Laplace later independently derived a more general statement of Bayes' theorem closer to the modern form.}% and was resposible for introducing many of the elements of what is now typically considered the Bayesian system of inference.}
This expression relating the posterior on the unknown parameters to the prior distribution and model of the observations is an example of \emph{Bayes' theorem}. Typically the product of the conditional densities $\pden{\rvct{y}|\rvct{x}}$ is termed the \emph{likelihood} and considered a function of the value $\vct{x}$ of the unknown parameters $\rvct{x}$, with the observed data values $\lbrace \vct{y}^{(n)} \rbrace_{n=1}^N$ fixed. The denominator of the right-hand side \eqref{eq:iid-data-posterior-density}, the marginal density on the observed variables, can be written as a integral marginalising out the parameters from the joint density
\begin{equation}\label{eq:model-evidence-definition}
  \pden{\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{y}^{(1)},\,...\,,\vct{y}^{(N)}) =
  \int_{\set{X}} \prod_{n=1}^N \pden{\rvct{y}|\rvct{x}}(\vct{y}^{(n)}\gvn\vct{x})\,
  \pden{\rvct{x}}(\vct{x}) \,\mu_{\rvct{x}}(\dr\vct{x}).
\end{equation}
\marginpar{A conditional density $\pden{\rvct{u}|\rvct{v}}$ is from the exponential family if it can be written as\\
$\pden{\rvct{u}|\rvct{v}}(\vct{u}\gvn\vct{v})=$
\\[1mm]
$\frac{h(\vct{u}) \exp \lpa \vct{\eta}(\vct{v})\tr\vct{t}(\vct{u})\rpa}{z(\vct{v})}$,
\\[1mm] with $\vct{\eta}(\vct{v})$ termed the \emph{natural parameters} and $\vct{t}(\vct{u})$ termed the \emph{sufficient statistics}.}
This term is often described as the \emph{marginal likelihood} or the \emph{model evidence}. Generally this integral will not have an analytic solution though there are exceptions to this in a few special cases. For example if the densities $\pden{\rvct{y}|\rvct{x}}$ and $\pden{\rvct{x}}$ are both of \emph{exponential family distributions} and form a {conjugate pair} such that the posterior density is in the same family as the prior density then \eqref{eq:model-evidence-definition} will have a closed-form solution. For models in which the parameters are discrete the integral in \eqref{eq:model-evidence-definition} corresponds to a summation and so is in theory exactly solvable, though if the total number of possible configurations of the parameters is very large this summation can be infeasible to compute in practice. If the parameters are instead real-valued but of a low-dimensionality it may be possible to use numerical quadrature methods \citep{davis1967numerical} to compute the integral in \eqref{eq:model-evidence-definition} to a reasonable accuracy. Quadrature methods involve evaluating the integrand across a grid of points and then computing a weighted sum of these values. For a fixed grid resolution however the cost of quadrature scales exponentially with the dimension of the space being integrated over - if $G$ points are used per dimension, for a $D$ dimensional parameter space evaluating \eqref{eq:model-evidence-definition} would require summing the joint density over $G^D$ parameter values.

For real-valued parameter spaces of a more than $\sim 10$ dimensions\footnote{The \texttt{C}-based implementation by Steven G. Johnson of an adaptive multi-dimensional quadrature algorithm \citep{berntsen1991adaptive} available at \url{https://github.com/stevengj/cubature} recommends using the package for integrals of up to around $D = 7$. Running a provided test cases for the integral of a Gaussian density across a $D$-dimensional space with a target error tolerance of $10^{-5}$ took around 2.5 seconds for $D=5$, 50 seconds for $D=6$ and 17 minutes for $D=7$ on one core of a desktop \acs{CPU}. Extrapolating the $\sim$ 20-fold increase in run time per dimension, for $D=10$ the run-time would be around 100 days.} 
%\footnote{With a grid of $G=10$ points per dimensions for $D=20$ a current high-end desktop processor with a theoretical peak performance of $5 \times 10^{11}$ \ac{FLOPS} would take on the order of years to compute the integral.} 
evaluating the model evidence term \eqref{eq:model-evidence-definition} is therefore typically computationally intractable. We can therefore often only evalulate the posterior density \eqref{eq:iid-data-posterior-density} up to an unknown constant. The posterior density itself is usually not of direct interest as it is only a proxy for describing the posterior distribution and is dependent on the particular model parameterisation chosen. However most quantities of interest from an inference perspective involve integrating functions against the posterior distribution and as with the model evidence these integrals will typically be intractable to compute exactly. 

For example under an \ac{IID} assumption the density of the \emph{predictive distribution} of a new data point $\rvct{y}^*$ given the previously observed data is formed by integrating $\pden{\rvct{y}|\rvct{x}}$ against the posterior distribution
\begin{equation}\label{eq:iid-predictive-distribution}
\begin{split}
  &\pden{\rvct{y}^*|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{y}^* \gvn \vct{y}^{(1)},\,...\,,\vct{y}^{(N)}) \\
  &\qquad = 
  \int_{\set{X}} 
    \pden{\rvct{y}|\rvct{x}}(\vct{y}^*\gvn\vct{x})\,
    \pden{\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{x} \gvn \vct{y}^{(1)},\,...\,,\vct{y}^{(N)})
  \,\mu_{\rvct{x}}(\dr \vct{x})
  \\
  & \qquad =
  \expc{\pden{\rvct{y}|\rvct{x}}(\vct{y}^*\gvn\rvct{x}) \gvn \rvct{y}^{(1)} = \vct{y}^{(1)},\,...\,,\rvct{y}^{(N)} = \vct{y}^{(N)}}.
\end{split}
\end{equation}
If we wish to for example minimise the expected prediction error under some loss function this will involve integrating against this predictive distribution and so as a sub-task integrating against the posterior distribution on the model parameters. Similarly evaluating statistics of the unknown parameters under the posterior such as their mean or covariance corresponds to computing conditional expectations. In general any inferential output which takes in to account all of the information available from the posterior distribution will involve integrating against the posterior and so the computation of integrals is the key computational task in inference.

As exact evaluation of the integrals of interest is usually intractable we must instead resort to \emph{approximate inference} methods which trade-off an introduction of some level of approximation for an increase in computational tractability. %In the next chapter we review some of the major approximate inference methods which have been proposed and which form the basis for the contributions of this thesis.

The \ac{IID} assumption is widely made in inference problems and although it will not be always be entirely valid in practice, it will often be a reasonable approximation. For real-valued parameter spaces $\set{X}$ and densities $\pden{\rvct{y}|\rvct{x}}$ and $\pden{\rvct{x}}$ meeting certain regularity conditions, if an \ac{IID} assumption is valid then the posterior distribution will asymptotically tend to a multivariate normal distribution as the number of data points $N$ tends to infinity \citep{hartigan1983bayes}. For inference in models of large \ac{IID} datasets where the conditions for asymptotic normality are met, while the dimensionality of the parameter space will often still require the use of approximate inference methods, the close to normal geometry of the posterior distribution will typically mean even relatively simple approximate inference methods can achieve good results. % and often the key computational issues are efficiently utilising the large amounts of data. 

In this thesis we will primarily be concerned with methods for performing inference in models which do not fit into this mould. In the following subsections we discuss some specific issues that can prove challenging to standard approximate inference approaches and which the methods contributed in this thesis are intended to help address.

% iid data - asymptoptic normality

%We will generally avoid the terms likelihood and marginal likelihood here and prefer to refer to the relevant conditional or marginal densities specifically using the notation introduced earlier in this chapter. The likelihood is usually formally defined as a function of the parameters given fixed values for the observed variables, with this usage arising from non-Bayesian \emph{maximum likelihood} methods which find values of the parameters which maximise the likelihood (given data). Under this definition it makes sense to refer to the likelihood of the parameters, but not the likelihood of observed variables (or observations / data). This leads to recommendations to refer to `the likelihood of the parameters given the [observed] data' \citep{mackay2003information}, which given the construct being discussed is actually a density on the observed data given parameter values is, in our opinion, not particularly clear. 

%Further attaching a special name to the entity distracts from it being simply a conditional density function and implies a, in our view unwarrantedly, privileged role in inference. The fundamental object required for performing inference is the joint distribution across observed and unobserved variables. In many cases a factorisation in to a `prior' marginal distribution on the unobserved variables (parameters) and conditional distribution on the observed variables given unobserved variables will be natural, but not always. Consider for example the task of inferring the pixel values an unobserved portion of an image given the observed pixel values in the remaining image. Here it will be typically be more natural to represent our prior beliefs (about plausible images) as a joint distribution on all the image pixels, observed and unobserved directly, rather than specifying a prior distribution on the unobserved pixels and conditional distribution of the observed pixel values given the unobserved pixels. A difference of this image inference problem from the more typical model parameter inference problems considered in Bayesian inference is that we would not typically consider the unobserved region of the image `causing' the observed pixels, while a direction of causality from parameters to observed data is often implicitly assumed in Bayesian inference problems. Probability theory and inference is in general however agnostic to causality, and it is valid to consider inference in models without positing a direct causal link between the unobserved and observed variables.

%The posterior distribution summarises our beliefs about the model parameters after observing data and so is central to Bayesian inference. Inference is sometimes described as the process of finding the posterior distribution

% posterior distribution
% evidence 

% prediction on new data
% summaries descriptions of parameters - mean, (co)variance
% key-role of integration and exponential scaling of quadrature with dimension.

% hierarchical latent variable models
%  - example Gaussian process models, hierarchical regression models
%  - ODW example?

% implicit models
%  - example simulators

% multimodal distributions
%  - Boltzmann machine

% model comparison

%In reality probabilistic modelling and inference are an iterative process with model criticism a key part of the loop \citep{box1980sampling,gelman2013philosophy}. We will discuss some of the (computational) issues involved in probabilistic model evaluation and comparison at the end of this chapter.

%\marginpar{Always write down the probability of everything.\\--Steve Gull}
%The first stage in any inference problem will be defining a probabilistic model for the problem at hand. A model embodies our assumptions about the problem, and in particular how we assume the quantities we observe are related to the unknown aspects that we wish to infer. Amongst the simplest, but also most commonly used, basic assumptions is that we observed a set of independent realisations 


\subsection{Hierarchical models}\label{subsec:hierachical-models-intro}

\begin{figure}	
\centering
\includetikz{hierachical-latent-variable-model-full-factor-graph}
\caption[Hierarchical latent variable model factor graph.]{Factor graph of a simple hierarchical latent variable model with $N$ observed variables $\rvct{y}^{(n)}$ each associated with a local latent variable $\rvct{z}^{(n)}$, with both observed and latent variables dependent on a set of global latent variables (parameters) $\rvct{x}$.}
\label{fig:hierarchical-latent-var-factor-graph}
\end{figure}

In the preceding discussion of inference in a model of a \ac{IID} dataset, it was assumed that the only unknown variables in the model were a set of parameters $\rvct{x}$, the quantity of which did not depend on the number of data points $N$. This structure can be overly restrictive with it common that the process being modelled includes unknown quantities associated with each observed variable. Models will therefore  often include local (per data point) latent variables in addition to a set of global latent variables (or parameters). This grouping structure in the observed and unobserved variables in a model can extend to multiple levels and such models often are termed \emph{hierarchical} or \emph{multilevel} models.

A simple example of a hierarchical model is shown as a factor graph in Figure \ref{fig:hierarchical-latent-var-factor-graph}. As in the factor graph in Figure \ref{fig:simple-iid-factor-graph} we assume there are $N$ observed variables $\lbrace \rvct{y}^{(n)} \rbrace_{n=1}^N$ and a vector of global latent variables $\rvct{x}$. We further define $N$ local latent variables $\lbrace \rvct{z}^{(n)} \rbrace_{n=1}^N$ paired with each observed variable. In Figure \ref{fig:hierarchical-latent-var-factor-graph} we assume the local latent and observed variables are conditionally independent given the global latent variables. More complex structures are also common - for example dynamical state space models for time series data assume dependencies between the latent variables corresponding to adjacent time points. %Variants on the structure shown in Figure \ref{fig:hierarchical-latent-var-factor-graph} encompass the basic form of probabilistic models commonly used in statistics and machine learning, such as latent Dirichlet allocation topic models \citep{blei2003latent} and Gaussian process regression and classification models \citep{rasmussen2006gaussian}.

Although powerful, the introduction of local latent variables in to models can significantly increase the complexity of inference. At a basic level, as the number of unobserved variables is now dependent on the data set size, the total dimensionality of the space which needs to be integrated over when performing inference will typically be much higher than for models with a fixed number of parameters. This means the need for inference methods which scale well with dimensionality is even more essential. The growth of the the number of unobserved variables with the data set size $N$ will typically also mean that we can no longer expect asymptotic normality of the full posterior. Typically the posterior distribution on the local and global latent variables will have a complex geometry, with strong dependencies between the global and local latent variables that can limit the performance of many standard approximate inference approaches \citep{betancourt2015hamiltonian}.

In some cases the posterior distributions of the local latent variables associated with the observed data will not be of direct interest to the downstream task. For example the conditional independence structure in Figure \ref{fig:hierarchical-latent-var-factor-graph} means that the predictive distribution on a new unseen datapoint $\rvct{y}^*$ given the observed data has density
\begin{equation}\label{eq:hier-lv-predictive-distribution}
\begin{split}
  &\pden{\rvct{y}^*|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{y}^* \gvn \vct{y}^{(1)},\,...\,,\vct{y}^{(N)}) \\
  &\qquad = 
  \int_{\set{Z}} \int_{\set{X}}
    \pden{\rvct{y}|\rvct{x},\rvct{z}}(\vct{y}^*\gvn\vct{x},\vct{z})\,
    \pden{\rvct{z}|\rvct{x}}(\vct{z}\gvn\vct{x})\\
  &\qquad \phantom{= \int_{\set{Z}} \int_{\set{X}}\,}
    \pden{\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}(\vct{x} \gvn \vct{y}^{(1)},\,...\,,\vct{y}^{(N)})
  \,\mu_{\rvct{x}}(\dr \vct{x})\,\mu_{\rvct{z}}(\dr \vct{z}).
\end{split}
\end{equation}
Predictions under the model will therefore not depend on the values of the local latent variables $\lbrace \rvct{z}^{(n)} \rbrace_{n=1}^N$, and so ideally we would marginalise out these variables from the full posterior distribution on all unobserved variables $\prob{\rvct{z}^{(1)},\,...\,,\rvct{z}^{(N)},\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}$ to obtain the posterior distribution on just the global latent variables $\prob{\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}$. The distribution $\prob{\rvct{x}|\rvct{y}^{(1)},\,...\,,\rvct{y}^{(N)}}$ is defined on a much lower dimensional space and will often have a simpler geometry which makes it more amenable to approximate inference methods, however generally the marginalisation over the local latent variables will not be analytically tractable. We can in some cases however approximately marginalise out the local latent variables - we discuss methods based on this idea in Chapter \ref{ch:pseudo-marginal-methods}.

\subsection{Simulator models}\label{subsec:implicit-models}

\begin{figure}[!t]
\centering
\begin{subfigure}[b]{\linewidth}
\vskip 0pt
\centering
\hrule
\vskip 3pt
%\begin{minipage}{0.7\linewidth}
\begin{algorithmic}
\small
\State $\vct{y}_0 \sim \nrm{\cdot \gvn \vct{\nu},\mtx{\Psi}}$
\State $\vct{x} \sim \nrm{\cdot \gvn \vct{\mu},\mtx{\Sigma}}$
\For {$t \in \lbr 1 \dots T\rbr$}
  \State $\vct{n}_{t-1} \sim \nrm{\cdot \gvn \vct{0},\idmtx}$
  \State $\vct{y}_{t} \gets \vct{y}_{t-1} + h \vct{m}(\vct{y}_{t-1},\vct{x}) - \frac{h}{2} \vct{s}(\vct{y}_{t-1},\vct{x})\odot\pd{\vct{s}}{\vct{y}}(\vct{y}_{t-1},\vct{x})$
  \State $\vct{y}_{t} \gets \vct{y}_{t}  + \sqrt{h} \, \vct{s}(\vct{y}_{t-1},\vct{z})\odot \vct{n}_{t-1} + \frac{h}{2} \vct{s}(\vct{y}_{t-1},\vct{x})\odot\pd{\vct{s}}{\vct{y}}(\vct{y}_{t-1},\vct{x}) \odot \vct{n}_{t-1}^2$
\EndFor
\end{algorithmic}
%\end{minipage}
\vskip 3pt
\hrule
\vskip 3pt
\captionsetup{justification=centering}
\caption{Pseudo-code for Milstein method integration of \ac{SDE} model. } %
\label{sfig:sim-model-code} %
\end{subfigure}%
\\[2ex]
\begin{subfigure}[b]{\linewidth}
\vskip 0pt
\centering
\includetikz{sde-simulation-factor-graph}
%\vskip 5pt
\caption{Directed factor graph of 3 time steps of \ac{SDE} simulation.}
\label{sfig:sim-model-factor-graph}
\end{subfigure}%
\caption[Simulator model example.]{Example of a simulator model corresponding to Milstein method integration of a set of \acsp{SDE}, $\dr \rvct{y}(t) = \vct{m}\lpa\rvct{y}(t),\rvct{x}\rpa \,\dr t + \vct{s}\lpa\rvct{y}(t),\rvct{x}\rpa \, \dr\rvct{n}(t)$, specified as pseudo-code in \subref{sfig:sim-model-code} and a directed factor graph in \subref{sfig:sim-model-factor-graph}. The dynamics of model are governed by parameters $\rvct{x}$. In the pseudo-code the notation $\sim$ followed by a distribution shorthand represents generating a value from the associated distribution.} % and assigning it to a variable.} %
\label{fig:simulator-model-example}
\end{figure}

The probabilistic models considered so far have been defined by explicitly specifying a density over the all the variables in the model, for example via a factor graph. Rather than defining the density on the variables in a model an alternative approach is for a process for generating values for the variables in a model to be specified procedurally in code, with the resulting joint density on the model variables then only implicitly defined. Such models are sometimes termed \emph{simulator} or \emph{implicit} models \citep{diggle1984monte}. %; we will use the term \emph{implicit generative model} here.

A common setting in which such models occur is the simulation of a mechanistic model of a physical process for example described by a set of \acfp{SDE}. In implementations of such simulator models, the stochasticity in the model will be introduced via draws from a pseudo-random number generator. Given these random inputs, the output of the simulator is then calculated as a series of deterministic operations and so can be described by a computation graph. The overall composition of directed factor nodes specifying the generation of random inputs from known densities by the random number generator and computation graph describing the operations performed by the simulator code together therefore define a directed factor graph. An example of a simulator model corresponding to approximate integration of a set of \acp{SDE} using the Milstein method \citep{mil1975approximate} is shown as both pseudo-code and a directed  factor graph in Figure \ref{fig:simulator-model-example}.

%If the observed variables had instead been the output of a deterministic factor where there was no bijective dependence on any of the parent variables (inputs to the deterministic factor), the change of variables formula \eqref{eq:change-of-variables-vector-bijective} would no longer have applied. Generally in such cases it will not be possible to analytically marginalise out a parent variable to give an explicit conditional density on the observed variable(s). %Models which do not admit explicit conditional densities on the observed variables are sometimes described as \emph{implicit models} \citep{diggle1984monte}, with simulator models being a common case.

\begin{figure}[t]
\centering
\begin{subfigure}[b]{.48\linewidth}
\centering
\includetikz{example-implicit-model-factor-graph}
\caption{Directed factor graph for model with two latent variables $(\rvar{x}_1, \rvar{x}_2)$, and an observed variable $\rvar{y}$.}
\label{sfig:simple-impl-factor-graph}
\end{subfigure}
~~
\begin{subfigure}[b]{.48\linewidth}
\centering
\includetikz{example-implicit-model-cond-plot}
\caption{Plot of marginal density on latent variables (contours) and set of values for which $\rvar{y} = 1$ (green curve).}
\label{sfig:example-implicit-model-cond-plot}
\end{subfigure}
\caption[Example of implicit probabilistic model.]{Simple example of an implicit probabilistic model where the observed variable is a non-bijective function of two latent variables.}
\label{fig:example-non-bijective-transform-factor-graph}
\end{figure}

The main complicating factor in performing inference in simulator models is the unavailability of an explicit density function on the model variables which is a prerequisite for most approximate inference methods. Computing a density function on the unobserved variables to be inferred (for example parameters of the dynamics of a \ac{SDE} model) and simulated observed variables that are conditioned on requires that all other random variables used in the model are marginalised over. In some cases this marginalisation may technically be possible to exactly solve and so a density function possible to compute in theory but the complexity of the model structure means that the density is unavailable in practice. 

In many cases however the density function may not be exactly evaluable even in theory. A key difference of simulator models from the probabilistic models considered previously is that the observed variables in the model are defined via deterministic transformations of other random variables. Using our above intuition that any simulator model can be expressed as a directed factor graph with deterministic factor nodes, this means that the observed variables in the graph correspond to the outputs of deterministic factors rather than the more usual case of the observed variables being connected to probabilistic factors.

An illustration of such a case for a simple three variable model is shown in Figure \ref{fig:example-non-bijective-transform-factor-graph}. Here the observed variable $\rvar{y}$ is a deterministic function of two latent (unobserved) variables $\rvar{x}_1$ and $\rvar{x}_2$. There is no analytic solution in terms of elementary functions for $\rvar{x}_1$ as a function of $\rvar{y}$ and $\rvar{x}_2$ or for $\rvar{x}_2$ as a function of $\rvar{x}_1$ and $\rvar{y}$. This means the Dirac delta term corresponding to the deterministic factor cannot be integrated out. Due to the presence of the Dirac delta the joint density $\pden{\rvar{y},\rvar{x}_1,\rvar{x}_2}$ is not well defined (the joint distribution $\prob{\rvar{y},\rvar{x}_1,\rvar{x}_2}$ is not absolutely continuous with respect to the Lebesgue measure) which complicates evaluations of conditional expectations such as $\expc{f(\rvar{x}_1,\rvar{x}_2) \gvn \rvar{y} = 1}$. In particular the set of $\rvar{x}_1$ and $\rvar{x}_2$ values corresponding to solutions to $\rvar{y} = y$ for an particular $y$ (illustrated for $y=1$ as the green curve in Figure \ref{sfig:example-implicit-model-cond-plot}) is an implicitly defined manifold (here a one-dimensional curve) in the $\rvar{x}_1$--$\rvar{x}_2$ space with zero Lebesgue measure, and the conditional distribution $\prob{\rvar{x}_1,\rvar{x}_2|\rvar{y}}$ has support only on this manifold.  %Therefore even though the dimensionality is low in this case we can not use simple quadrature to evaluate conditional expectations without some further form of approximation. 
We explore methods for performing inference in implicit models in Chapter \ref{ch:differentiable-generative-models}.

%\subsection{Multimodal distributions}

%A particularly challenging property of probability distributions for approximate inference methods to deal with is multi-modality. For distributions on real-valued spaces multi-modality can be loosely defined as the presence of multiple distinct regions of high probability density separated by regions of low probability density. %When the target distribution is the posterior distribution after conditioning the observed variables in a model on data, multi-modality generally corresponds to there being some level of competing explanations for the observations or inherent ambiguity in the observed data. For instance give a probabilistic model relating observed two-dimensional projections of the positions of points in a three-dimensional space 
%Multi-modality presents a challenge to approximate inference methods as most methods which scale to high-dimensions are iterative methods which utilise only local information about the density function on each update. % - for example updates to the state of the chain in \ac{MCMC} methods or updates to the parameters of the approximate density in optimisation-based methods. 
%This means that these methods can often end up approximating only one or a few nearby modes in a multi-modal target distribution and further provide no indication in the inference output that modes have been missed.
 
\subsection{Undirected models}

\begin{figure}[!t]
\vskip 0pt
\centering
\includetikz{boltzmann-machine-factor-graph}
%\vskip 5pt
\caption[Boltzmann machine factor graph.]{Five unit Boltzmann machine factor graph.}
\label{fig:boltzmann-machine-factor-graph}
\end{figure}

When introducing factor graphs we stated that factors can be both directed and undirected. In the preceding discussion we concentrated on directed models, both in the form of model explicitly specified via directed factor graphs as in the examples in Figure \ref{fig:simple-iid-factor-graph} and \ref{fig:hierarchical-latent-var-factor-graph}, and simulator models which as we argued in the previous subsection can be considered as implicitly defining a directed factor graph. A key defining feature of models corresponding to directed factor graphs is that they are natural descriptions of generative processes, with independent sampling from the joint distribution across model variables typically simple to perform via ancestral sampling (in the case of simulator models this being their defining feature).

Undirected models (which we will use here to mean models specified by factor graphs consisting solely of undirected factors) offer a complementary approach for defining a probabilistic model. Each undirected factor node is associated with a non-negative function defining a factor in the joint density across all model variables. Unlike a directed factor, this function does not correspond to a conditional or marginal density. Instead it describes a more general notion of `compatibility' between the values of sets of variables in the model, defining a series of soft constraints as to which joint configurations are plausible (corresponding to a high value for the factor) or implausible (corresponding to a low model). This makes undirected models a natural representation for models of systems of mutually interacting components without a specific directivity in those interactions. For example they are commonly used in models of images to represent dependencies between pixel values, to model networks of stochastically spiking neurons in the brain and models of magnetic interactions in particle lattices. Unlike directed models, generating samples from the joint distribution on variables in an undirected model is typically a non-trivial task, with no general equivalent to ancestral sampling. %Further the joint density can typically only be evaluated up to an unknown normalising constant, with the integral needed to evaluate this constant often intractable for models involving a large number of variables or complex potentials.

A particularly common form of undirected model is the \emph{Boltzmann machine} \citep{ackley1985learning} also known as a \emph{pairwise binary Markov random field} \citep{kindermann1980markov} or in statistical physics settings an \emph{Ising spin model} \citep{ising1925beitrag}. A Boltzmann machine consists of a set of binary random variables $\rvct{s} = [\rvar{s}_1 ~ \cdots ~ \rvar{s}_D]\tr$; these are typically chosen to take values in $\set{U} = \fset{0,1}^D$ or $\set{S} = \fset{-1,+1}^D$ - we will favour $\set{S} = \fset{-1,+1}^D$. The joint distribution across the variables is parameterised by a symmetric weight matrix $\mtx{W} \in \reals^{D\times D}$ and a bias vector $\vct{b} \in \reals^D$ and defined as
\begin{equation}\label{eq:boltzmann-machine-distribution}
  \pden{\rvct{s}}(\vct{s}) =
  \frac{1}{Z} \exp\lpa \frac{1}{2}\vct{s}\tr\mtx{W}\vct{s} + \vct{s}\tr\vct{b}\rpa,
  ~~
  Z = \sum_{\vct{s} \in \set{S}} \exp\lpa \frac{1}{2}\vct{s}\tr\mtx{W}\vct{s} + \vct{s}\tr\vct{b}\rpa.
\end{equation}
%with the $Z$ a normalising constant defined as
%\begin{equation}\label{eq:boltzmann-machine-normalising-constant}
%  Z = \sum_{\vct{s} \in \set{S}} \exp\lpa \frac{1}{2}\vct{s}\tr\mtx{W}\vct{s} + \vct{s}\tr\vct{b}\rpa.
%\end{equation}
Evaluation of the normalising constant $Z$ involves a summation over $2^D$ states and so for large $D$ quickly become intractable to compute exactly. Evaluation of expectations with respect to the Boltzmann machine distribution also involves an exhaustive summation across $S$ and so will also be intractable for high $D$. %Because of this it is intractable to generate independent samples from general Boltzmann machine distributions for high $D$ by for example dividing the unit interval $[0,1]$ in to $2^D$ sub-intervals of lengths equal to the probability of the individual state configurations, as we can only evaluate what the \emph{relative} length of such intervals should be, not the total length.

If $\rvct{s}_1$ and $\rvct{s}_2$ are an arbitrary partition of the variables in $\rvct{s}$ then importantly the conditional distribution $\prob{\rvct{s}_1|\rvct{s}_2}$ will also be Boltzmann machine distributions. However unless the dimensionality of $\rvct{s}_1$ is small enough that exhaustive summation over its possible states is feasible, then evaluating normalising constants of this conditional distribution and expectations with respect to it will also be intractable. Therefore inference in Boltzmann machines conditioned on observations of part of the state can be considered as a special case of computing expectations and the normalising constants of (non-conditioned) Boltzmann machine distributions, with the same challenges applying to both.

Figure \ref{fig:boltzmann-machine-factor-graph} shows the factor graph for a Boltzmann machine distribution on five binary random variables $\lbrace \rvar{s}_i \rbrace_{i=1}^5$. Each of the weights $W_{ij}$ defines an undirected factor between a pair of variables $\rvar{s}_iW_{ij}\rvar{s}_j$. As the variables take on signed binary values, this factor is equal to $W_{ij}$ when the variables are equal and so take the same sign and equal to $-W_{ij}$ when the variables take differing values. If $W_{ij}$ is positive this factor therefore favours states where $\rvar{s}_i$ and $\rvar{s}_j$ are in the same configuration, while if $W_{ij}$ is negative states with $\rvar{s}_i$ and $\rvar{s}_j$ in opposing configurations are preferred.

Boltzmann machine systems with a mixture of positive and negative weights will often be \emph{frustrated} with no one global configuration which satisfies the preferences specified by each weight, and instead there being multiple states which each locally satisfy a subset of the soft constraints specified by the weights. This typically leads to a highly multi-modal distribution on the states of the system, with collections of nearby\footnote{Nearby here being in terms of the Hamming distance between the binary states.} states of high-probability separated sets of states with very low probability. 

This multi-modality typically makes frustrated Boltzmann machines very challenging distributions to perform approximate inference with. In particular methods based on constructing Markov chains which explore the state of the system tend to converge very slowly as they will typically remain confined to a particular high-probability region of the state space for many iterations. In Chapter \ref{ch:continuous-tempering} we will consider methods for constructing Markov chains with improved exploration of challenging multi-modal target distributions, including methods for estimating expectations and normalising constants of frustrated Boltzmann machine distributions.

\subsection{Model comparison}

So far we have discussed inferring the unobserved variables in a single fixed model. An important second level of inference is comparing competing models for the same observed data. This can be treated consistently within the probabilistic framework we have discussed. 

\marginpar{Ockham's Razor is a philosophical principle, commonly attributed to the 14th century Franciscan friar William of Ockham, that states if there exist multiple explanations for observations, all else being equal we should prefer the simplest.}
Given observed data, we would like to be able to make a judgement as to which of two (or more) proposed models better describes the data. To be useful this comparison must take into account the relative complexity of the models; a model with more free variables will generally be able to fit observed data more closely, however \emph{Ockham's Razor} (and corresponding empirical evidence of the loss of predictive power of overly complex models) suggests we should prefer simpler models where possible. By marginalising over the free,  unobserved variables in a model, probabilistic model comparison automatically embodies Ockham's Razor \citep{mackay2003information}. 
%We will first pose the model inference problem in general terms before returning to the \emph{Observing Dark Worlds} problem to give a concrete example.

%\begin{figure}
%\centering
%\includetikz{model-comparison-factor-graph}
%%\vskip 5pt
%\caption[Model comparison factor graph.]{Factor graph for inference over multiple models.} %
%\label{fig:model-comparison-factor-graph}
%\end{figure}

A concrete structure for model comparison is to assume that there are a finite set of $M$ models, indexed by an \emph{indicator} variable $\rvar{m} \in \fset{1 \dots M}$. All models share the same observed variables\footnote{For notational simplicity here we assume all observed variables have been concatenated in to one vector and similarly for the unobserved variables, with any internal model factorisation structure such as discussed in the preceding sections omitted.} $\rvct{y}$, and there are a set of per model vectors of unobserved variables $\fset{\rvct{x}_m}_{m=1}^M$ which are assumed to be independent (before conditioning on observations). More complex structures could be assumed such as the models sharing a set of common unobserved variables, however we only consider the case of independent models here. The joint density on the observations, model indicator and latent variables is then assumed to factorise as
\begin{equation}\label{eq:multi-model-joint}
\begin{split}
  &\pden{\rvct{y},\rvar{m},\rvct{x}_1,\,...\, ,\rvct{x}_M}
  (\vct{y},m,\vct{x}_1,...\, ,\vct{x}_M) =\\[-2mm]
  &\qquad\qquad
  \pden{\rvct{x}|\rvar{m},\rvct{z}_m}(\vct{y}\gvn m,\vct{x}_m)\,
  \pden{\rvar{m}}(m)\,
  \prod_{n=1}^M \pden{\rvct{x}_n}(\vct{x}_n).
\end{split}
\end{equation}
The marginal density on the model indicator $\pden{\rvar{m}}$ represents our prior beliefs about the relative probabilities of the models before observing data. Importantly the value of the model indicator variable $\rvar{m}$ selects the relevant per model conditional density on the observed variables given latent variables $\pden{\rvct{y}|\rvar{m},\rvct{x}_m}$; this represents the assumption that conditioned on the model indicator assuming a particular model index $m$ the observed variables are conditionally independent of the latent variables of all other models $\rvct{y} \perp \fset{\rvct{x}_n}_{n\neq m} \gvn \rvar{m} = m$. %An extension to factor graphs, \emph{gates} \citep{minka2009gates}, can be used to represent such context-dependent conditional independencies. Figure \ref{fig:model-comparison-factor-graph} shows a gated factor graph of equation \ref{eq:multi-model-joint}, with the gate indicated by the dashed box. %The semantics of the gate are that any edges from factors or variables nodes within the gate box to variables or factor outside the gate are only active when the gating variable, indicated by the the variable

%\footnote{As $\rvar{m}$ is a discrete random variable the probability of the event of $\rvar{m}$ taking a value in the singleton set $\fset{m}$ given that $\rvct{y} = \vct{y}$ is equal to the density $\pden{\rvar{m}|\rvct{y}}(m\gvn\vct{y})$.}
Given this computational set up, the task in model comparison is then to compute the relative probabilities of each of the models given observed data. These probabilities are given by
\begin{equation}\label{eq:model-posterior}
  \pden{\rvar{m}|\rvct{y}}(m\gvn\vct{y}) = 
  \frac{\pden{\rvct{y}|\rvar{m}}(\vct{y}\gvn m)\,\pden{\rvar{m}}(m)}
  {\sum_{n=1}^M \lpa \pden{\rvct{y}|\rvar{m}}(\vct{y}\gvn n)\,\pden{\rvar{m}}(n)\rpa},
\end{equation}
which can be seen as a direct analogue to Bayes' theorem for the posterior density on unobserved random variables for a single model. The key quantities needed to evaluate the model posterior probabilities are the marginal densities $\pden{\rvct{y}|\rvar{m}}(\vct{y}\gvn m)$ evaluated at the observed data. Computing these values requires marginalising out the unobserved variables from the per model joint densities $\pden{\rvct{y},\rvct{x}_m|\rvar{m}}$
\begin{equation}\label{eq:model-marginal-den}
  \pden{\rvct{y}|\rvar{m}}(\vct{y}\gvn m) = 
  \int_{\set{X}_m} \pden{\rvct{y}|\rvar{m},\rvct{x}_m}(\vct{y}\gvn m, \vct{x}) \pden{\rvct{x}_m}(\vct{x})
  \,\dr\vct{x}.
\end{equation}
This value is equivalent to \eqref{eq:model-evidence-definition} for a single model, this explaining the naming of this term as the \emph{model evidence}.

As described previously, evaluating the model evidence requires integrating across the space of all unobserved variables. The key computational challenge in being able to perform probabilistic model comparison with complex high dimensional models is therefore again being able to efficiently to compute integrals in high dimensional spaces. Unlike the integrals required for making predictions using a single model however, the model evidence integral cannot be naturally expressed as an expectation of a function with respect to the posterior distribution. This can complicate approximate computation of model evidence terms compared to other quantities involved in inference. In Chapter \ref{ch:continuous-tempering} we will consider extensions to a class of methods proposed for estimating model evidence terms.

\section{Summary}

Probabilistic modelling offers a natural way to formalise our beliefs and assumptions about a problem and make inferences given those beliefs. Once a model has been defined the theoretical basis of the inference process is elegantly simple. Underlying this simplicity however are some very significant implementation challenges. The key computational task is the evaluation of integrals across high-dimensional spaces, which typically do not have closed form solutions and are intractable to compute using standard numerical integration approaches. 

This intractability necessitates the use of approximate inference methods, the focus of this thesis.  In particular we propose several novel extensions to \ac{MCMC} methods, a class of approaches for drawing dependent samples from high-dimensional target distributions. In the next chapter we review the basic Monte Carlo method for integration and associated methods for generating and using independent pseudo-random variates to estimate the integrals. We then introduce the key Markov chain theory underlying \ac{MCMC} methods and review some key existing \ac{MCMC} algorithms. We will then conclude with an outline of the remainder of the thesis, in particular giving a a summary of the novel contributions made and how these relate to the specific inference problems discussed in the last section of this chapter.

%the discussion of existing  and a statement of the novel contributions made.

%We conclude the next chapter with a discussion of some of the difficulties in applying \ac{MCMC} methods to the inference problems outlined at the end of this chapter, and 


%In particular we contribute methods designed to help in four specific settings which can prove challenging to existing inference methods: 
%\begin{itemize}
%  \item hierachical latent variable models with complex dependencies between the global and local latent variables,
%  \item simulator models without an explicit density function on the model variables,
%  \item models inducing multi-modal distributions across the variables being inferred
%  \item and estimation of model evidence terms for model comparison purposes. 
%\end{itemize}
%In the next chapter we review the appr

%reviews the approximate inference methods which form the basis for the novel approaches proposed in this thesis. The basics of the Monte Carlo method of integration are first introduced, and rejection and importance sampling discussed as specific instances of the approach, with key ideas from both methods being used in the approaches discussed later in the thesis. The key topic of Markov chain Monte Carlo methods is then introduced. Some of the key standard algorithms for constructing Markov chains which leave a desired target distribution invariant are reviewed, beginning with the Metropolis--Hastings and Gibbs sampling, before concluding with discussions of two auxiliary variable approaches, slice sampling and Hamiltonian Monte Carlo, which are used as the basis for the methods proposed in later chapters. Although not the main focus of this thesis, a brief review of the key optimisation-based approximate inference methods is also given as these are utilised within \ac{MCMC} frameworks in several of the approaches discussed in the later chapters.


%In this introduction we reviewed the probabilistic modelling tools and notation used in the rest of the work in this thesis. We motivated that the evaluation of integrals with respect to probability distributions on high-dimensional spaces was the key computational task in inference, with typically these integrals neither having analytic solutions or being amenable to quadrature based numerical integration methods in the settings of interest. We concluded by introducing four specific settings which can prove challenging to existing inference methods and are the focus of the methods introduced in this thesis: hierachical latent variable models with complex dependencies between the global and local latent variables; simulator models without an explicit density function on the model variables; multi-modality in the target distribution; estimation of model evidence terms for model comparison purposes. 
%
%The structure of the rest of thesis is as follows
%\begin{description}
%  \item[Chapter 2] reviews the approximate inference methods which form the basis for the novel approaches proposed in this thesis. The basics of the Monte Carlo method of integration are first introduced, and rejection and importance sampling discussed as specific instances of the approach, with key ideas from both methods being used in the approaches discussed later in the thesis. The key topic of Markov chain Monte Carlo methods is then introduced. Some of the key standard algorithms for constructing Markov chains which leave a desired target distribution invariant are reviewed, beginning with the Metropolis--Hastings and Gibbs sampling, before concluding with discussions of two auxiliary variable approaches, slice sampling and Hamiltonian Monte Carlo, which are used as the basis for the methods proposed in later chapters. Although not the main focus of this thesis, a brief review of the key optimisation-based approximate inference methods is also given as these are utilised within \ac{MCMC} frameworks in several of the approaches discussed in the later chapters.
%  
%  \item[Chapter 3] introduces the \emph{pseudo-marginal} framework for constructing a Markov chain given access to only an unbiased non-negative estimator for the density of the target distribution of interest. Inference in hierarchical latent variable models where we wish to marginalise over the local latent variables is used as a motivating example for applying the framework. 
%  \item[Chapter 4]
%  \item[Chapter 5]
%  \item[Chapter 6]
%\end{description}
%In this chapter we reviewed the probabilistic modelling framework that will form the basis for the methods we will introduce in the rest of the thesis. We began by introducing some of the underlying concepts from probability theory, in particular focusing on the manipulation random variables which are a key abstraction for explaining much of theory behind the methods in this thesis.  %We illustrated the use of factor graphs to efficiently communicate the structure of complex probabilistic models and discussed their close links to computation graphs which allow efficient calculation of the derivatives of the outputs of complex functions of a large numbers of variables with respect to their inputs. 
%We then motivated the computational challenges of performing inference in complex probabilistic models involving large numbers of unobserved variables. In particular we identified the key computational requirement as being able to evaluate integrals across high-dimensional spaces. In the next chapter we will introduce some of the computational methods which have been proposed to address the challenges of finding solutions to inference problems. These approximate inference approaches will form the basis for the novel methods proposed in the later chapters in this thesis.

%As a concrete example of model comparison, we can consider comparing the model proposed with